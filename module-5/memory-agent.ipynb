{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory Agent\n",
    "- Until now, the agents we built,\n",
    "    * saved all the information\n",
    "    * saved either to a **profile** schema or to a **collection** schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Task Manager\n",
    "\n",
    "- Now, we will build a chatbot that,\n",
    "    * decides when to save something in the long-term memory\n",
    "    * decides whether to store the information in the **user_profile** schema or in the **to_do_collection** schema\n",
    "- That mean, our agent will have **semantic** as well as **procedural** memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model=\"gpt-4o\",temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visibility into Trustcall Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Memory(BaseModel):\n",
    "    content: str = Field(description=\"The main content of the memory. For example: User expressed interest in learning about French.\")\n",
    "\n",
    "class MemoryCollection(BaseModel):\n",
    "    memories: list[Memory] = Field(description=\"A list of memories about the user.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a `listener` to the Trustcall extractor\n",
    "- This will pass runs from the extractor's execution to a class, `Spy` that we will define\n",
    "- Our spy class will extract information about what tool calls were made by Trustcall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['LANGSMITH_TRACING'] = 'false'\n",
    "from trustcall import create_extractor\n",
    "\n",
    "# Inspect the tool_calls made by Trustcall\n",
    "class Spy:\n",
    "    def __init__(self):\n",
    "        self.called_tools = []\n",
    "    \n",
    "    def __call__(self,run):\n",
    "        # Collect information about the tool calls made by the extractor.\n",
    "        q = [run]\n",
    "        while q:\n",
    "            r = q.pop()\n",
    "            if r.child_runs:\n",
    "                q.extend(r.child_runs)\n",
    "            if r.run_type == \"chat_model\":\n",
    "                self.called_tools.append(\n",
    "                    r.outputs['generations'][0][0]['message']['kwargs']['tool_calls']\n",
    "                )\n",
    "# Initilaize the spy\n",
    "spy =Spy()\n",
    "\n",
    "# Create the extractor\n",
    "trustcall_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Memory],\n",
    "    tool_choice=\"Memory\",\n",
    "    enable_inserts=True,\n",
    ")\n",
    "\n",
    "# Add the spy as a listener\n",
    "trustcall_extractor_see_all_tool_calls = trustcall_extractor.with_listeners(on_end=spy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableLambda(coerce_inputs)\n",
       "| <langgraph.graph.state.CompiledStateGraph object at 0x000001BB798B3F10>\n",
       "| RunnableLambda(filter_state), config_factories=[<function Runnable.with_listeners.<locals>.<lambda> at 0x000001BB77B95260>])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trustcall_extractor_see_all_tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Kj2z2HPjDUUkKXTUB6Wip2Aa', 'function': {'arguments': '{\"content\":\"Manan had a nice bike ride in San Francisco this morning.\"}', 'name': 'Memory'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 110, 'total_tokens': 127, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'finish_reason': 'stop', 'logprobs': None}, id='run-43dae252-b347-4f40-a6a8-6952543b0ea6-0', tool_calls=[{'name': 'Memory', 'args': {'content': 'Manan had a nice bike ride in San Francisco this morning.'}, 'id': 'call_Kj2z2HPjDUUkKXTUB6Wip2Aa', 'type': 'tool_call'}], usage_metadata={'input_tokens': 110, 'output_tokens': 17, 'total_tokens': 127})],\n",
       " 'responses': [Memory(content='Manan had a nice bike ride in San Francisco this morning.')],\n",
       " 'response_metadata': [{'id': 'call_Kj2z2HPjDUUkKXTUB6Wip2Aa'}],\n",
       " 'attempts': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# Instruction\n",
    "instruction = \"\"\"Extract memories from the following conversation:\"\"\"\n",
    "\n",
    "# Conversation\n",
    "conversation = [HumanMessage(content=\"Hi, I'm Manan.\"), \n",
    "                AIMessage(content=\"Nice to meet you, Manan.\"), \n",
    "                HumanMessage(content=\"This morning I had a nice bike ride in San Francisco.\")]\n",
    "\n",
    "# Invoke the extractor\n",
    "result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=instruction)] + conversation})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0',\n",
       "  'Memory',\n",
       "  {'content': 'Manan had a nice bike ride in San Francisco this morning.'})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update the conversation\n",
    "updated_conversation = [AIMessage(content=\"That's great, did you do after?\"), \n",
    "                        HumanMessage(content=\"I went to Tartine and ate a croissant.\"),                        \n",
    "                        AIMessage(content=\"What else is on your mind?\"),\n",
    "                        HumanMessage(content=\"I was thinking about my Japan, and going back this winter!\"),]\n",
    "\n",
    "# Update the instruction\n",
    "system_msg = \"\"\"Update existing memories and create new ones based on the following conversation:\"\"\"\n",
    "\n",
    "# We'll save existing memories, giving them an ID, key (tool name), and value\n",
    "tool_name = \"Memory\"\n",
    "existing_memories = [(str(i), tool_name, memory.model_dump()) for i, memory in enumerate(result[\"responses\"])] if result[\"responses\"] else None\n",
    "existing_memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [AIMessage(content='', additional_kwargs={'updated_docs': {'call_OI4wMesVOscn7gf1DF6UNfPc': '0'}}, id='1282a927-69ab-4d71-8298-1544e543b2ac', tool_calls=[{'name': 'Memory', 'args': {'content': 'Manan had a nice bike ride in San Francisco this morning. After the ride, he went to Tartine and ate a croissant.'}, 'id': 'call_OI4wMesVOscn7gf1DF6UNfPc', 'type': 'tool_call'}, {'name': 'Memory', 'args': {'content': 'Manan was thinking about his trip to Japan and considering going back this winter.'}, 'id': 'call_srwKdFA6bio5Egr1UkH0XOLM', 'type': 'tool_call'}])],\n",
       " 'responses': [Memory(content='Manan had a nice bike ride in San Francisco this morning. After the ride, he went to Tartine and ate a croissant.'),\n",
       "  Memory(content='Manan was thinking about his trip to Japan and considering going back this winter.')],\n",
       " 'response_metadata': [{'id': 'call_OI4wMesVOscn7gf1DF6UNfPc',\n",
       "   'json_doc_id': '0'},\n",
       "  {'id': 'call_srwKdFA6bio5Egr1UkH0XOLM'}],\n",
       " 'attempts': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoke the extractor with our updated conversation and existing memories\n",
    "result = trustcall_extractor_see_all_tool_calls.invoke({\"messages\": updated_conversation, \n",
    "                                                        \"existing\": existing_memories})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'call_OI4wMesVOscn7gf1DF6UNfPc', 'json_doc_id': '0'}\n",
      "{'id': 'call_srwKdFA6bio5Egr1UkH0XOLM'}\n"
     ]
    }
   ],
   "source": [
    "# Metadata contains the tool call  \n",
    "for m in result[\"response_metadata\"]: \n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_OI4wMesVOscn7gf1DF6UNfPc)\n",
      " Call ID: call_OI4wMesVOscn7gf1DF6UNfPc\n",
      "  Args:\n",
      "    content: Manan had a nice bike ride in San Francisco this morning. After the ride, he went to Tartine and ate a croissant.\n",
      "  Memory (call_srwKdFA6bio5Egr1UkH0XOLM)\n",
      " Call ID: call_srwKdFA6bio5Egr1UkH0XOLM\n",
      "  Args:\n",
      "    content: Manan was thinking about his trip to Japan and considering going back this winter.\n"
     ]
    }
   ],
   "source": [
    "# Messages contain the tool calls\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Manan had a nice bike ride in San Francisco this morning. After the ride, he went to Tartine and ate a croissant.'\n",
      "content='Manan was thinking about his trip to Japan and considering going back this winter.'\n"
     ]
    }
   ],
   "source": [
    "# Parsed responses\n",
    "for m in result[\"responses\"]:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'name': 'PatchDoc',\n",
       "   'args': {'json_doc_id': '0',\n",
       "    'planned_edits': 'Add the new memory about going to Tartine and eating a croissant after the bike ride. This involves appending a new sentence to the existing content field in the Memory schema.',\n",
       "    'patches': [{'op': 'replace',\n",
       "      'path': '/content',\n",
       "      'value': 'Manan had a nice bike ride in San Francisco this morning. After the ride, he went to Tartine and ate a croissant.'}]},\n",
       "   'id': 'call_OI4wMesVOscn7gf1DF6UNfPc',\n",
       "   'type': 'tool_call'},\n",
       "  {'name': 'Memory',\n",
       "   'args': {'content': 'Manan was thinking about his trip to Japan and considering going back this winter.'},\n",
       "   'id': 'call_srwKdFA6bio5Egr1UkH0XOLM',\n",
       "   'type': 'tool_call'}]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the tool calls made by Trustcall\n",
    "spy.called_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0 updated:\n",
      "Plan: Add the new memory about going to Tartine and eating a croissant after the bike ride. This involves appending a new sentence to the existing content field in the Memory schema.\n",
      "Added content: Manan had a nice bike ride in San Francisco this morning. After the ride, he went to Tartine and ate a croissant.\n",
      "\n",
      "New Memory created:\n",
      "Content: {'content': 'Manan was thinking about his trip to Japan and considering going back this winter.'}\n"
     ]
    }
   ],
   "source": [
    "def extract_tool_info(tool_calls, schema_name=\"Memory\"):\n",
    "    \"\"\"Extract information from tool calls for both patches and new memories.\n",
    "    \n",
    "    Args:\n",
    "        tool_calls: List of tool calls from the model\n",
    "        schema_name: Name of the schema tool (e.g., \"Memory\", \"ToDo\", \"Profile\")\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize list of changes\n",
    "    changes = []\n",
    "    \n",
    "    for call_group in tool_calls:\n",
    "        for call in call_group:\n",
    "            if call['name'] == 'PatchDoc':\n",
    "                changes.append({\n",
    "                    'type': 'update',\n",
    "                    'doc_id': call['args']['json_doc_id'],\n",
    "                    'planned_edits': call['args']['planned_edits'],\n",
    "                    'value': call['args']['patches'][0]['value']\n",
    "                })\n",
    "            elif call['name'] == schema_name:\n",
    "                changes.append({\n",
    "                    'type': 'new',\n",
    "                    'value': call['args']\n",
    "                })\n",
    "\n",
    "    # Format results as a single string\n",
    "    result_parts = []\n",
    "    for change in changes:\n",
    "        if change['type'] == 'update':\n",
    "            result_parts.append(\n",
    "                f\"Document {change['doc_id']} updated:\\n\"\n",
    "                f\"Plan: {change['planned_edits']}\\n\"\n",
    "                f\"Added content: {change['value']}\"\n",
    "            )\n",
    "        else:\n",
    "            result_parts.append(\n",
    "                f\"New {schema_name} created:\\n\"\n",
    "                f\"Content: {change['value']}\"\n",
    "            )\n",
    "    \n",
    "    return \"\\n\\n\".join(result_parts)\n",
    "\n",
    "# Inspect spy.called_tools to see exactly what happened during the extraction\n",
    "schema_name = \"Memory\"\n",
    "changes = extract_tool_info(spy.called_tools, schema_name)\n",
    "print(changes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an Agent\n",
    "- We will build a sort of `ReAct` agent.\n",
    "\n",
    "Our agent will have three types of memory:\n",
    "- `Profile`: Create or update a user profile\n",
    "- `Collection`: Add or Update elements to a To-Do List\n",
    "- `Instructions` about how to create/updates To-Do Elements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For structured output from the agent about which memory to update, let's create a class\n",
    "from typing import TypedDict, Literal\n",
    "\n",
    "class UpdateMemory(TypedDict):\n",
    "    \"\"\"Decision about which memory to update\"\"\"\n",
    "    update_type: Literal[\"user\", \"todo\", \"instructions\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Definition\n",
    "- We use a `binary router` to decide whether to update/create memory or not\n",
    "- We deal with memory in the `write_memory` node like before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Profile and ToDo Schemas \n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, List, Literal\n",
    "from datetime import datetime\n",
    "\n",
    "class Profile(BaseModel):\n",
    "    \"\"\"\"User Profile schema\"\"\"\n",
    "    name: Optional[str] = Field(description=\"The name of the user\")\n",
    "    location: Optional[str] = Field(description=\"The location of the user\")\n",
    "    job_title: Optional[str] = Field(description=\"The job title of the user\")\n",
    "    # The default_factory=list means that if no value is provided for 'connections', it will default to an empty list.\n",
    "    connections: List[str] = Field(description=\"The list of connections of the user\", default_factory=list)\n",
    "    interests: List[str] = Field(description=\"The list of interests of the user\", default_factory=list)\n",
    "\n",
    "class ToDo(BaseModel):\n",
    "    \"\"\"A collection of To-Do items containing information about the task\"\"\"\n",
    "    task: str = Field(description=\"The task to be completed\")\n",
    "    time_to_complete: Optional[int] = Field(description=\"The time to complete the task\")\n",
    "    deadline: Optional[datetime] = Field(description=\"The deadline of the task\", default=None)\n",
    "    solutions: list[str] = Field(description=\"The solutions to the task\", min_items=1, default_factory=list)\n",
    "    status: Literal[\"not started\", \"in progress\", \"done\", \"archived\"] = Field(description=\"The status of the task\", default=\"not started\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Master Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes in the user input, profile, todo and instructions and decides whether and which tool to call\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import MessagesState\n",
    "from langgraph.store.memory import InMemoryStore, BaseStore\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# Main Prompt\n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"You are a helpful chatbot. \n",
    "\n",
    "You are designed to be a companion to a user, helping them keep track of their ToDo list.\n",
    "\n",
    "You have a long term memory which keeps track of three things:\n",
    "1. The user's profile (general information about them) \n",
    "2. The user's ToDo list\n",
    "3. General instructions for updating the ToDo list\n",
    "\n",
    "Here is the current User Profile (may be empty if no information has been collected yet):\n",
    "<user_profile>\n",
    "{user_profile}\n",
    "</user_profile>\n",
    "\n",
    "Here is the current ToDo List (may be empty if no tasks have been added yet):\n",
    "<todo>\n",
    "{todo}\n",
    "</todo>\n",
    "\n",
    "Here are the current user-specified preferences for updating the ToDo list (may be empty if no preferences have been specified yet):\n",
    "<instructions>\n",
    "{instructions}\n",
    "</instructions>\n",
    "\n",
    "Here are your instructions for reasoning about the user's messages:\n",
    "\n",
    "1. Reason carefully about the user's messages as presented below. \n",
    "\n",
    "2. Decide whether any of the your long-term memory should be updated:\n",
    "- If personal information was provided about the user, update the user's profile by calling UpdateMemory tool with type `user`\n",
    "- If tasks are mentioned, update the ToDo list by calling UpdateMemory tool with type `todo`\n",
    "- If the user has specified preferences for how to update the ToDo list, update the instructions by calling UpdateMemory tool with type `instructions`\n",
    "\n",
    "3. Tell the user that you have updated your memory, if appropriate:\n",
    "- Do not tell the user you have updated the user's profile\n",
    "- Tell the user them when you update the todo list\n",
    "- Do not tell the user that you have updated instructions\n",
    "\n",
    "4. Err on the side of updating the todo list. No need to ask for explicit permission.\n",
    "\n",
    "5. Respond naturally to user user after a tool call was made to save memories, or if no tool call was made.\"\"\"\n",
    "\n",
    "# Node Definition\n",
    "def task_mAIstro(state: MessagesState, store: BaseStore, config: RunnableConfig):\n",
    "    # Get the memories from the store\n",
    "    user_id = config['configurable']['user_id']\n",
    "    \n",
    "    # Get the profile\n",
    "    namespace = ('profile',user_id)\n",
    "    memories = store.search(namespace)\n",
    "    ## Format the memories\n",
    "    if memories:\n",
    "        user_profile = memories[0].value\n",
    "    else:\n",
    "        user_profile = None\n",
    "    \n",
    "    # Get the ToDo Items\n",
    "    namespace = ('todo', user_id)\n",
    "    memories = store.search(namespace)\n",
    "    todo = '\\n'.join(f\"{item.value}\" for item in memories)\n",
    "    \n",
    "    # Retrieve custom instructions\n",
    "    namespace = (\"instructions\", user_id)\n",
    "    memories = store.search(namespace)\n",
    "    if memories:\n",
    "        instructions = memories[0].value\n",
    "    else:\n",
    "        instructions = \"\"\n",
    "    \n",
    "    system_msg = MODEL_SYSTEM_MESSAGE.format(user_profile=user_profile, todo=todo, instructions=instructions)\n",
    "\n",
    "    # Respond using memory as well as the chat history\n",
    "    response = model.bind_tools([UpdateMemory], parallel_tool_calls=False).invoke([SystemMessage(content=system_msg)]+state[\"messages\"])\n",
    "\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node 1: For Updating User Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trustcall import create_extractor\n",
    "from langchain_core.messages import merge_message_runs\n",
    "import uuid\n",
    "\n",
    "# Trustcall Extractor for updating the profile\n",
    "profile_extractor = create_extractor(model,\n",
    "                                       tools=[Profile],\n",
    "                                       tool_choice=\"Profile\")\n",
    "\n",
    "# Prompt for updating the user_profile\n",
    "TRUSTCALL_INSTRUCTION = \"\"\"Reflect on following interaction. \n",
    "\n",
    "Use the provided tools to retain any necessary memories about the user. \n",
    "\n",
    "Use parallel tool calling to handle updates and insertions simultaneously.\n",
    "\n",
    "System Time: {time}\"\"\"\n",
    "\n",
    "# Create a function that extracts memories, invokes trustcall to get the patches and updates the memories\n",
    "def update_profile(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"Reflect on the chat history and update the memory collection.\"\"\"\n",
    "\n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Define the namespace for the memories\n",
    "    namespace = (\"profile\", user_id)\n",
    "\n",
    "    # Retrieve the most recent memories for context\n",
    "    existing_items = store.search(namespace)\n",
    "\n",
    "    # Format the memory for the prompt\n",
    "    tool_name = 'Profile'\n",
    "    existing_memories = ([(item.key, tool_name, item.value) for item in existing_items] if existing_items else None)\n",
    "\n",
    "    # Format the prompt and call the extractor\n",
    "    TRUSTCALL_INSTRUCTION_FORMATTED=TRUSTCALL_INSTRUCTION.format(time=datetime.now().isoformat())\n",
    "    updated_messages=list(merge_message_runs(messages=[SystemMessage(content=TRUSTCALL_INSTRUCTION_FORMATTED)] + state[\"messages\"][:-1]))\n",
    "\n",
    "    # Invoke the extractor\n",
    "    result = profile_extractor.invoke({\"messages\": updated_messages, \n",
    "                                         \"existing\": existing_memories})\n",
    "    \n",
    "    # Update the Profile\n",
    "    for r, r_meta in zip(result['responses'], result['response_metadata']):\n",
    "        store.put(namespace, key = r_meta.get('json_doc_id', str(uuid.uuid4())), value = r.model_dump(mode='json'))\n",
    "    \n",
    "    # We must return a confirmation to the llm that a tool_call has been made successfully, if any\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "\n",
    "    return {\"messages\": [{\"role\": \"tool\", \"content\": \"updated profile\", \"tool_call_id\":tool_calls[0]['id']}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node 2: For Updating ToDo Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_todos(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Reflect on the chat history and update the memory collection.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Define the namespace for the memories\n",
    "    namespace = (\"todo\", user_id)\n",
    "\n",
    "    # Retrieve the most recent memories for context\n",
    "    existing_items = store.search(namespace)\n",
    "\n",
    "    # Format the existing memories for the Trustcall extractor\n",
    "    tool_name = \"ToDo\"\n",
    "    existing_memories = ([(existing_item.key, tool_name, existing_item.value)\n",
    "                          for existing_item in existing_items]\n",
    "                          if existing_items\n",
    "                          else None\n",
    "                        )\n",
    "\n",
    "    # Merge the chat history and the instruction\n",
    "    TRUSTCALL_INSTRUCTION_FORMATTED=TRUSTCALL_INSTRUCTION.format(time=datetime.now().isoformat())\n",
    "    updated_messages=list(merge_message_runs(messages=[SystemMessage(content=TRUSTCALL_INSTRUCTION_FORMATTED)] + state[\"messages\"][:-1]))\n",
    "\n",
    "    # Initialize the spy for visibility into the tool calls made by Trustcall\n",
    "    spy = Spy()\n",
    "    \n",
    "    # Create the Trustcall extractor for updating the ToDo list \n",
    "    todo_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[ToDo],\n",
    "    tool_choice=tool_name,\n",
    "    enable_inserts=True\n",
    "    ).with_listeners(on_end=spy)\n",
    "\n",
    "    # Invoke the extractor\n",
    "    result = todo_extractor.invoke({\"messages\": updated_messages, \n",
    "                                    \"existing\": existing_memories})\n",
    "\n",
    "    # Save the memories from Trustcall to the store\n",
    "    for r, rmeta in zip(result[\"responses\"], result[\"response_metadata\"]):\n",
    "        store.put(namespace,\n",
    "                  rmeta.get(\"json_doc_id\", str(uuid.uuid4())),\n",
    "                  r.model_dump(mode=\"json\"),\n",
    "            )\n",
    "        \n",
    "    # Respond to the tool call made in task_mAIstro, confirming the update\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "\n",
    "    # Extract the changes made by Trustcall and add the the ToolMessage returned to Main Node\n",
    "    todo_update_msg = extract_tool_info(spy.called_tools, tool_name)\n",
    "    return {\"messages\": [{\"role\": \"tool\", \"content\": todo_update_msg, \"tool_call_id\":tool_calls[0]['id']}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node 3: For Updating Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instructions for updating the ToDo list\n",
    "CREATE_INSTRUCTIONS = \"\"\"Reflect on the following interaction.\n",
    "\n",
    "Based on this interaction, update your instructions for how to update ToDo list items. \n",
    "\n",
    "Use any feedback from the user to update how they like to have items added, etc.\n",
    "\n",
    "Your current instructions are:\n",
    "\n",
    "<current_instructions>\n",
    "{current_instructions}\n",
    "</current_instructions>\"\"\"\n",
    "\n",
    "def update_instructions(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Reflect on the chat history and update the memory collection.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    \n",
    "    namespace = (\"instructions\", user_id)\n",
    "\n",
    "    existing_memory = store.get(namespace, \"user_instructions\")\n",
    "        \n",
    "    # Format the memory in the system prompt\n",
    "    system_msg = CREATE_INSTRUCTIONS.format(current_instructions=existing_memory.value if existing_memory else None)\n",
    "    new_memory = model.invoke([SystemMessage(content=system_msg)]+state['messages'][:-1] + [HumanMessage(content=\"Please update the instructions based on the conversation\")])\n",
    "\n",
    "    # Overwrite the existing memory in the store \n",
    "    key = \"user_instructions\"\n",
    "    store.put(namespace, key, {\"memory\": new_memory.content})\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "    return {\"messages\": [{\"role\": \"tool\", \"content\": \"updated instructions\", \"tool_call_id\":tool_calls[0]['id']}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Edge: Routing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional edge\n",
    "def route_message(state: MessagesState, config: RunnableConfig, store: BaseStore) -> Literal[END, \"update_todos\", \"update_instructions\", \"update_profile\"]:\n",
    "\n",
    "    \"\"\"Reflect on the memories and chat history to decide whether to update the memory collection.\"\"\"\n",
    "    message = state['messages'][-1]\n",
    "    if len(message.tool_calls) ==0:\n",
    "        return END\n",
    "    else:\n",
    "        tool_call = message.tool_calls[0]\n",
    "        if tool_call['args']['update_type'] == \"user\":\n",
    "            return \"update_profile\"\n",
    "        elif tool_call['args']['update_type'] == \"todo\":\n",
    "            return \"update_todos\"\n",
    "        elif tool_call['args']['update_type'] == \"instructions\":\n",
    "            return \"update_instructions\"\n",
    "        else:\n",
    "            raise ValueError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Image\n",
    "# Create the graph + all nodes\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define the flow of the memory extraction process\n",
    "builder.add_node(task_mAIstro)\n",
    "builder.add_node(\"update_todos\",update_todos)\n",
    "builder.add_node(\"update_profile\",update_profile)\n",
    "builder.add_node(\"update_instructions\",update_instructions)\n",
    "builder.add_edge(START, \"task_mAIstro\")\n",
    "builder.add_conditional_edges(\"task_mAIstro\", route_message)\n",
    "builder.add_edge(\"update_todos\", \"task_mAIstro\")\n",
    "builder.add_edge(\"update_profile\", \"task_mAIstro\")\n",
    "builder.add_edge(\"update_instructions\", \"task_mAIstro\")\n",
    "\n",
    "# Store for long-term (across-thread) memory\n",
    "across_thread_memory = InMemoryStore()\n",
    "\n",
    "# Checkpointer for short-term (within-thread) memory\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# We compile the graph with the checkpointer and store\n",
    "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "My name is Manan. I am a student at IIT-Kharagpur. I love Coding!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_6Wy7Rf5oj6gchmTPswvNCodM)\n",
      " Call ID: call_6Wy7Rf5oj6gchmTPswvNCodM\n",
      "  Args:\n",
      "    update_type: user\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "updated profile\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Nice to meet you, Manan! It's great to hear that you're a student at IIT-Kharagpur and that you love coding. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"Manan\"}}\n",
    "\n",
    "# User input to create a profile memory\n",
    "input_messages = [HumanMessage(content=\"My name is Manan. I am a student at IIT-Kharagpur. I love Coding!\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I want to finish the 'Introduction_to_Langgraph Course!'\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_SH15PDEHdaCZVytMiaHa4zZQ)\n",
      " Call ID: call_SH15PDEHdaCZVytMiaHa4zZQ\n",
      "  Args:\n",
      "    update_type: todo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "New ToDo created:\n",
      "Content: {'task': \"Finish the 'Introduction_to_Langgraph Course'\", 'time_to_complete': 5, 'deadline': None, 'solutions': ['Set aside dedicated study time each day', 'Review course materials and take notes', 'Complete all assignments and quizzes', 'Join study groups or forums for discussion'], 'status': 'not started'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've added \"Finish the 'Introduction_to_Langgraph Course'\" to your ToDo list. If you need any help or strategies to complete it, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# User input for a ToDo\n",
    "input_messages = [HumanMessage(content=\"I want to finish the 'Introduction_to_Langgraph Course!'\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "When creating or updating ToDo items, make sure to include a motivational quote!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_SkbavUOYMqLAnk9mwWYHJnyI)\n",
      " Call ID: call_SkbavUOYMqLAnk9mwWYHJnyI\n",
      "  Args:\n",
      "    update_type: instructions\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "updated instructions\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Got it! I'll make sure to include a motivational quote whenever I create or update your ToDo items. If there's anything else you need, just let me know!\n"
     ]
    }
   ],
   "source": [
    "# User input to update instructions for creating ToDos\n",
    "input_messages = [HumanMessage(content=\"When creating or updating ToDo items, make sure to include a motivational quote!\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'memory': '<current_instructions>\\nWhen creating or updating ToDo list items, include a motivational quote to inspire and encourage the user.\\n</current_instructions>'}\n"
     ]
    }
   ],
   "source": [
    "# Check for updated instructions\n",
    "user_id = \"Manan\"\n",
    "\n",
    "# Search \n",
    "for memory in across_thread_memory.search((\"instructions\", user_id)):\n",
    "    print(memory.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I need to learn basic DSA, SQL for my interviews :( )\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_5jhH2AaFIT6vRCYGF0nxoea1)\n",
      " Call ID: call_5jhH2AaFIT6vRCYGF0nxoea1\n",
      "  Args:\n",
      "    update_type: todo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "New ToDo created:\n",
      "Content: {'task': 'Learn basic DSA for interviews', 'time_to_complete': 10, 'solutions': ['Set a study schedule', 'Use online resources and tutorials', 'Practice coding problems', 'Join study groups'], 'status': 'not started'}\n",
      "\n",
      "New ToDo created:\n",
      "Content: {'task': 'Learn basic SQL for interviews', 'time_to_complete': 8, 'solutions': ['Follow a structured course', 'Practice with real databases', 'Work on SQL projects', 'Review SQL interview questions'], 'status': 'not started'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've added \"Learn basic DSA for interviews\" and \"Learn basic SQL for interviews\" to your ToDo list. Remember, \"The only way to do great work is to love what you do.\" Keep pushing forward, and you'll do great in your interviews! If you need any resources or tips, feel free to ask.\n"
     ]
    }
   ],
   "source": [
    "# User input for a ToDo\n",
    "input_messages = [HumanMessage(content=\"I need to learn basic DSA, SQL for my interviews :( )\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "{'task': \"Finish the 'Introduction_to_Langgraph Course'\", 'time_to_complete': 5, 'deadline': None, 'solutions': ['Set aside dedicated study time each day', 'Review course materials and take notes', 'Complete all assignments and quizzes', 'Join study groups or forums for discussion'], 'status': 'not started'}\n",
      "--------------------------------------------------\n",
      "{'task': 'Learn basic DSA for interviews', 'time_to_complete': 10, 'deadline': None, 'solutions': ['Set a study schedule', 'Use online resources and tutorials', 'Practice coding problems', 'Join study groups'], 'status': 'not started'}\n",
      "--------------------------------------------------\n",
      "{'task': 'Learn basic SQL for interviews', 'time_to_complete': 8, 'deadline': None, 'solutions': ['Follow a structured course', 'Practice with real databases', 'Work on SQL projects', 'Review SQL interview questions'], 'status': 'not started'}\n"
     ]
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"Manan\"\n",
    "\n",
    "# Search \n",
    "for memory in across_thread_memory.search((\"todo\", user_id)):\n",
    "    print(\"-\"*50)\n",
    "    print(memory.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "For the langgraph lessons, I need to get that done by the first week of July!.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_DTxQp4PLANyJoV3yDfF8xYD9)\n",
      " Call ID: call_DTxQp4PLANyJoV3yDfF8xYD9\n",
      "  Args:\n",
      "    update_type: todo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Document be2a67e9-14e3-4d72-897d-5aa2a3f5bd6e updated:\n",
      "Plan: 1. Add a deadline to the task 'Finish the Introduction_to_Langgraph Course' with the date set to the end of the first week of July 2025. This involves updating the 'deadline' field.\n",
      "2. Add a motivational quote to the task to inspire the user to complete it.\n",
      "Added content: 2025-07-07T23:59:59\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've updated your ToDo list with a deadline for the \"Introduction_to_Langgraph Course\" to be completed by the first week of July 2025. Remember, \"Success is not the key to happiness. Happiness is the key to success. If you love what you are doing, you will be successful.\" Keep up the great work!\n"
     ]
    }
   ],
   "source": [
    "# User input to update an existing ToDo\n",
    "input_messages = [HumanMessage(content=\"For the langgraph lessons, I need to get that done by the first week of July!.\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying with a New Thread\n",
    "- All the long-term memories are retained!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I have 30 minutes, what tasks can I get done?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Let's take a look at your current ToDo list to see what tasks might fit into a 30-minute window:\n",
      "\n",
      "1. **Finish the 'Introduction_to_Langgraph Course'** - Estimated time: 5 hours\n",
      "2. **Learn basic DSA for interviews** - Estimated time: 10 hours\n",
      "3. **Learn basic SQL for interviews** - Estimated time: 8 hours\n",
      "\n",
      "While none of these tasks can be fully completed in 30 minutes, you can make progress on any of them. Here are some suggestions:\n",
      "\n",
      "- **Introduction_to_Langgraph Course**: Spend 30 minutes reviewing course materials or taking notes.\n",
      "- **Learn basic DSA**: Use the time to practice a few coding problems or watch a short tutorial.\n",
      "- **Learn basic SQL**: You could follow a short lesson or practice a few SQL queries.\n",
      "\n",
      "Remember, every small step counts! Let me know if you'd like to add a new task or update any existing ones.\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"Manan\"}}\n",
    "\n",
    "# Chat with the chatbot\n",
    "input_messages = [HumanMessage(content=\"I have 30 minutes, what tasks can I get done?\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Thanks! Let's start learning SQL. Give me something to start.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Great choice! Here's a simple plan to get you started with SQL in your 30-minute session:\n",
      "\n",
      "1. **Follow a Structured Course**: Begin with a basic tutorial or course. Websites like W3Schools or Codecademy offer free introductory lessons on SQL. You can start with understanding the basic SQL syntax and commands like `SELECT`, `FROM`, and `WHERE`.\n",
      "\n",
      "2. **Practice with Real Databases**: If you have access to a database, try running some basic queries. If not, you can use online platforms like SQLFiddle or DB-Fiddle to practice.\n",
      "\n",
      "3. **Work on SQL Projects**: Consider starting a small project, like creating a simple database for a personal project or hobby. This will help you apply what you learn.\n",
      "\n",
      "4. **Review SQL Interview Questions**: If you're preparing for interviews, look at common SQL interview questions and try to solve them.\n",
      "\n",
      "Here's a motivational quote to keep you inspired: \"The secret of getting ahead is getting started.\"\n",
      "\n",
      "Let me know if you want to update your ToDo list with this progress!\n"
     ]
    }
   ],
   "source": [
    "# Chat with the chatbot\n",
    "input_messages = [HumanMessage(content=\"Thanks! Let's start learning SQL. Give me something to start.\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
