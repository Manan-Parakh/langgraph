{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot with Collection Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model=\"gpt-4o\",temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Collection Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Memory(BaseModel):\n",
    "    content: str = Field('The main content of the memory. For example: \"User expressed interest in reading books\"')\n",
    "\n",
    "class MemoryCollection(BaseModel):\n",
    "    memories: List[Memory] = Field('A list of Memories about the user')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `with_structured_output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MemoryCollection(memories=[Memory(content=\"User's name is Manan.\"), Memory(content='Manan likes to read books.')])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "structured_model = model.with_structured_output(MemoryCollection)\n",
    "\n",
    "# System Prompt\n",
    "system_message = \"\"\"You are a helpful assistant whose task is to store details about the user in the given format\"\"\"\n",
    "human_message = \"Hi! My name is Manan. I like to read books.\"\n",
    "response = structured_model.invoke([SystemMessage(content=system_message),HumanMessage(content=human_message)])\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': \"User's name is Manan.\"}\n",
      "{'content': 'Manan likes to read books.'}\n"
     ]
    }
   ],
   "source": [
    "for r in response.memories:\n",
    "    print(r.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save all the memories to the store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "in_memory_store = InMemoryStore()\n",
    "\n",
    "user_id = \"1\"\n",
    "namespace_for_memory = (user_id,'memories')\n",
    "\n",
    "for i, memory in enumerate(response.memories):\n",
    "    key = f\"memory_{i}\"\n",
    "    value = memory.model_dump()\n",
    "    # Put the memory in the store \n",
    "    in_memory_store.put(namespace_for_memory, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "{'namespace': ['1', 'memories'], 'key': 'memory_0', 'value': {'content': \"User's name is Manan.\"}, 'created_at': '2025-06-29T20:35:58.911828+00:00', 'updated_at': '2025-06-29T20:35:58.911828+00:00', 'score': None}\n",
      "--------------------------------------------------\n",
      "{'namespace': ['1', 'memories'], 'key': 'memory_1', 'value': {'content': 'Manan likes to read books.'}, 'created_at': '2025-06-29T20:35:58.911828+00:00', 'updated_at': '2025-06-29T20:35:58.911828+00:00', 'score': None}\n"
     ]
    }
   ],
   "source": [
    "for memory in in_memory_store.search(namespace_for_memory):\n",
    "    print(\"-\"*50)\n",
    "    print(memory.dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating Collection Schema\n",
    "- Problems: We want to be able to add as well as modify existing memories\n",
    "- Solution: Trustcall\n",
    "\n",
    "* We provide the schema for each memory: `Memory`\n",
    "* We can supply `enable_inserts = True` to allow the extractor to insert new memories to the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['LANGSMITH_TRACING'] = 'false'\n",
    "from trustcall import create_extractor\n",
    "\n",
    "trustcall_extractor = create_extractor(model,\n",
    "                                       tools = [Memory],\n",
    "                                       tool_choice='Memory',\n",
    "                                       enable_inserts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith tracing is off\n"
     ]
    }
   ],
   "source": [
    "print(\"LangSmith tracing is\", \"on\" if os.environ.get(\"LANGSMITH_TRACING\", \"\").lower() == \"true\" else \"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fvATKGZGh8vsPjwGGK6Oobh7', 'function': {'arguments': '{\"content\":\"Manan has completed more than 80 percent of the langgraph course.\"}', 'name': 'Memory'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 116, 'total_tokens': 135, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'finish_reason': 'stop', 'logprobs': None}, id='run-0b7f8693-4f6a-463f-8991-65a297b60780-0', tool_calls=[{'name': 'Memory', 'args': {'content': 'Manan has completed more than 80 percent of the langgraph course.'}, 'id': 'call_fvATKGZGh8vsPjwGGK6Oobh7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 116, 'output_tokens': 19, 'total_tokens': 135})],\n",
       " 'responses': [Memory(content='Manan has completed more than 80 percent of the langgraph course.')],\n",
       " 'response_metadata': [{'id': 'call_fvATKGZGh8vsPjwGGK6Oobh7'}],\n",
       " 'attempts': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# Instruction\n",
    "instruction = \"\"\"Extract memories from the following conversation:\"\"\"\n",
    "\n",
    "# Conversation\n",
    "conversation = [HumanMessage(content=\"Hi, I'm Manan.\"), \n",
    "                AIMessage(content=\"Nice to meet you, Manan.\"), \n",
    "                HumanMessage(content=\"I have finished more than 80 percent of the langgraph course!\")]\n",
    "\n",
    "# Invoke the extractor\n",
    "result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=instruction)] + conversation})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_fvATKGZGh8vsPjwGGK6Oobh7)\n",
      " Call ID: call_fvATKGZGh8vsPjwGGK6Oobh7\n",
      "  Args:\n",
      "    content: Manan has completed more than 80 percent of the langgraph course.\n"
     ]
    }
   ],
   "source": [
    "result['messages'][0].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Memory(content='Manan has completed more than 80 percent of the langgraph course.')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['responses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0',\n",
       "  'Memory',\n",
       "  {'content': 'Manan has completed more than 80 percent of the langgraph course.'})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update the conversation\n",
    "updated_conversation = [AIMessage(content=\"That's great, did you enjoy that?\"), \n",
    "                        HumanMessage(content=\"Yes! I built a working Agentic RAG flow using Langgraph. Made good projects while learning itself!\"),                        \n",
    "                        AIMessage(content=\"What else is on your mind?\"),\n",
    "                        HumanMessage(content=\"I am planning to learn Ambient Agents after this!\"),]\n",
    "\n",
    "# Update the instruction\n",
    "system_message = \"Update existing memories and create new ones based on the following conversation\"\n",
    "\n",
    "# Providing the existing memories with ID, key (tool name) and value\n",
    "tool_name = 'Memory'\n",
    "existing_memories = [(str(i), tool_name, memory.model_dump()) for i, memory in enumerate(result['responses'])] if result['responses'] else None\n",
    "existing_memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [AIMessage(content='', additional_kwargs={'updated_docs': {'call_k5XW1YfsyGYRAmiVZNw929LR': '0'}}, id='0383e2bf-5c93-4f16-81a8-9a88b2a2f1ff', tool_calls=[{'name': 'Memory', 'args': {'content': 'Manan has completed more than 80 percent of the Langgraph course, enjoyed building a working Agentic RAG flow, made good projects while learning, and is planning to learn about Ambient Agents next.'}, 'id': 'call_k5XW1YfsyGYRAmiVZNw929LR', 'type': 'tool_call'}])],\n",
       " 'responses': [Memory(content='Manan has completed more than 80 percent of the Langgraph course, enjoyed building a working Agentic RAG flow, made good projects while learning, and is planning to learn about Ambient Agents next.')],\n",
       " 'response_metadata': [{'id': 'call_k5XW1YfsyGYRAmiVZNw929LR',\n",
       "   'json_doc_id': '0'}],\n",
       " 'attempts': 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoke the extractor with updated_conversation and existing_memories\n",
    "result = trustcall_extractor.invoke({'messages':updated_conversation, 'existing': existing_memories})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_k5XW1YfsyGYRAmiVZNw929LR)\n",
      " Call ID: call_k5XW1YfsyGYRAmiVZNw929LR\n",
      "  Args:\n",
      "    content: Manan has completed more than 80 percent of the Langgraph course, enjoyed building a working Agentic RAG flow, made good projects while learning, and is planning to learn about Ambient Agents next.\n"
     ]
    }
   ],
   "source": [
    "result['messages'][0].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'call_k5XW1YfsyGYRAmiVZNw929LR', 'json_doc_id': '0'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['response_metadata']\n",
    "# It contains the json_doc_id which it is planning to edit! -> Editing an existing memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Memory(content='Manan has completed more than 80 percent of the Langgraph course, enjoyed building a working Agentic RAG flow, made good projects while learning, and is planning to learn about Ambient Agents next.')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['responses']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbot with Collection Schema Updating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The user's name is Manan\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = Memory(content=\"The user's name is Manan\")\n",
    "memory.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Image\n",
    "from langgraph.graph import START,END,StateGraph\n",
    "from langgraph.graph.message import MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.store.memory import InMemoryStore, BaseStore\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from uuid import uuid4\n",
    "\n",
    "# Define the Collection Schema\n",
    "class Memory(BaseModel):\n",
    "    content: str = Field(description=\"The main content of the memory. For example: 'The user likes to read books and code!'\")\n",
    "\n",
    "# Trustcall create_extractor\n",
    "trustcall_extractor = create_extractor(model,\n",
    "                                       tools = [Memory],\n",
    "                                       tool_choice='Memory',\n",
    "                                       enable_inserts=True)\n",
    "\n",
    "# Define the first node that is a simple chatbot responding to user based on the memory \n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"You are a helpful chatbot. \n",
    "You have a long term memory which keeps track of information you learn about the user over time.\n",
    "Current Memory (may include updated memories from this conversation): \n",
    "{memory}\"\"\"\n",
    "\n",
    "def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"Load the memory and chat with the user\"\"\"\n",
    "\n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve memory from the store\n",
    "    namespace = (\"memories\", user_id)\n",
    "    memories = store.search(namespace)\n",
    "\n",
    "    # Based on the memory structure, format it to make it prompt friendly\n",
    "    info = \"\\n\".join(f\"-{mem.value['content']}\" for mem in memories)\n",
    "    system_message = MODEL_SYSTEM_MESSAGE.format(memory = info)\n",
    "\n",
    "    # Respond using memory as well as the chat history\n",
    "    response = model.invoke([SystemMessage(content=system_message)]+state[\"messages\"])\n",
    "\n",
    "    return {\"messages\": response}\n",
    "\n",
    "# Node 2 to update the memory based on updated_conversation\n",
    "# Trustcall instruction\n",
    "TRUSTCALL_INSTRUCTION = \"\"\"Reflect on following interaction. \n",
    "Use the provided tools to retain any necessary memories about the user. \n",
    "Use parallel tool calling to handle updates and insertions simultaneously:\"\"\"\n",
    "\n",
    "def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve memory from the store\n",
    "    namespace = (\"memories\", user_id)\n",
    "    existing_items = store.search(namespace)\n",
    "\n",
    "    # Existing memories must be in the form: ID, key(Tool Name), value\n",
    "    tool_name = 'Memory'\n",
    "    existing_memories = [(existing_item.key, tool_name, existing_item.value) for existing_item in existing_items] if existing_items else None\n",
    "\n",
    "    result = trustcall_extractor.invoke({'messages': [SystemMessage(content=system_message)] + state['messages'],\n",
    "                                'existing': existing_memories})\n",
    "    \n",
    "    # Save the memories to the store\n",
    "    for r, rmeta in zip(result['responses'], result['response_metadata']):\n",
    "        store.put(namespace,\n",
    "                  rmeta.get('json_doc_id',uuid4()),\n",
    "                  r.model_dump(mode=\"json\"))\n",
    "\n",
    "# Define the graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_node(\"write_memory\", write_memory)\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_edge(\"call_model\", \"write_memory\")\n",
    "builder.add_edge(\"write_memory\", END)\n",
    "\n",
    "# Store for long-term (across-thread) memory\n",
    "across_thread_memory = InMemoryStore()\n",
    "\n",
    "# Checkpointer for short-term (within-thread) memory\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# Compile the graph with the checkpointer fir and store\n",
    "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, my name is Manan\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello, Manan! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"3\"}}\n",
    "\n",
    "# User input \n",
    "input_messages = [HumanMessage(content=\"Hi, my name is Manan\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I like to read books and code!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's great, Manan! Reading and coding are both excellent hobbies. Do you have any favorite books or coding projects you're working on?\n"
     ]
    }
   ],
   "source": [
    "# User input \n",
    "input_messages = [HumanMessage(content=\"I like to read books and code!\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'namespace': ['memories', '3'], 'key': '782dbb72-8602-467d-ad72-da8f6f20b9b2', 'value': {'content': \"The user's full name is Manan Parakh. Manan likes to read books and code.\"}, 'created_at': '2025-06-30T01:53:08.230191+00:00', 'updated_at': '2025-06-30T01:53:08.230191+00:00', 'score': None}\n"
     ]
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"3\"\n",
    "namespace = (\"memories\", user_id)\n",
    "memories = across_thread_memory.search(namespace)\n",
    "for m in memories:\n",
    "    print(m.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I live in India!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thanks for sharing, Manan! Living in India must be fascinating with its rich culture and history. Is there anything specific about India that you particularly enjoy or find inspiring?\n"
     ]
    }
   ],
   "source": [
    "# User input \n",
    "input_messages = [HumanMessage(content=\"I live in India!\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'namespace': ['memories', '3'], 'key': '782dbb72-8602-467d-ad72-da8f6f20b9b2', 'value': {'content': \"The user's full name is Manan Parakh. Manan likes to read books and code. Manan lives in India.\"}, 'created_at': '2025-06-30T01:54:40.281512+00:00', 'updated_at': '2025-06-30T01:54:40.281512+00:00', 'score': None}\n",
      "{'namespace': ['memories', '3'], 'key': '085599d8-7104-4098-a1b0-ac68d424e8d9', 'value': {'content': 'Manan lives in India.'}, 'created_at': '2025-06-30T01:54:40.281512+00:00', 'updated_at': '2025-06-30T01:54:40.281512+00:00', 'score': None}\n"
     ]
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"3\"\n",
    "namespace = (\"memories\", user_id)\n",
    "memories = across_thread_memory.search(namespace)\n",
    "for m in memories:\n",
    "    print(m.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I live in Rajnandgaon, Chhattisgarh, India!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Rajnandgaon sounds like an interesting place! Chhattisgarh is known for its natural beauty and cultural heritage. Is there anything specific you enjoy about living in Rajnandgaon?\n"
     ]
    }
   ],
   "source": [
    "# User input \n",
    "input_messages = [HumanMessage(content=\"I live in Rajnandgaon, Chhattisgarh, India!\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'namespace': ['memories', '3'], 'key': '782dbb72-8602-467d-ad72-da8f6f20b9b2', 'value': {'content': \"The user's full name is Manan Parakh. Manan likes to read books and code. Manan lives in Rajnandgaon, Chhattisgarh, India.\"}, 'created_at': '2025-06-30T01:55:13.020163+00:00', 'updated_at': '2025-06-30T01:55:13.020163+00:00', 'score': None}\n",
      "{'namespace': ['memories', '3'], 'key': '085599d8-7104-4098-a1b0-ac68d424e8d9', 'value': {'content': 'Manan lives in Rajnandgaon, Chhattisgarh, India.'}, 'created_at': '2025-06-30T01:55:13.020163+00:00', 'updated_at': '2025-06-30T01:55:13.020163+00:00', 'score': None}\n"
     ]
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"3\"\n",
    "namespace = (\"memories\", user_id)\n",
    "memories = across_thread_memory.search(namespace)\n",
    "for m in memories:\n",
    "    print(m.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
