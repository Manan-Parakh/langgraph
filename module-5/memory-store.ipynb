{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot with Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "in_memory_store = InMemoryStore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When storing objects in `store`, provide\n",
    "- `namespace`: a tuple (similar to directory)\n",
    "- `key`: similar to filename\n",
    "- `value`: similar to file content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"1\"\n",
    "namespace_for_memory = (user_id,'memories')\n",
    "\n",
    "# Save a Memory to the namespace as key,value pair\n",
    "key = str(uuid.uuid4()) # uuid4 -> random\n",
    "\n",
    "# The value has to be a dictionary\n",
    "value = {\"animal_preference\":\"I like cats\"}\n",
    "\n",
    "# Save the memory \n",
    "in_memory_store.put(namespace_for_memory, key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `search` to retrieve results as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Item(namespace=['1', 'memories'], key='0293d219-d738-4480-afbf-4fccdca5ef08', value={'animal_preference': 'I like cats'}, created_at='2025-06-27T21:00:09.131605+00:00', updated_at='2025-06-27T21:00:09.131605+00:00', score=None)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memories = in_memory_store.search(namespace_for_memory)\n",
    "memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': ['1', 'memories'],\n",
       " 'key': '0293d219-d738-4480-afbf-4fccdca5ef08',\n",
       " 'value': {'animal_preference': 'I like cats'},\n",
       " 'created_at': '2025-06-27T21:00:09.131605+00:00',\n",
       " 'updated_at': '2025-06-27T21:00:09.131605+00:00',\n",
       " 'score': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metadata\n",
    "memories[0].dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `get` to get the result - requires namespace and key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': ['1', 'memories'],\n",
       " 'key': '0293d219-d738-4480-afbf-4fccdca5ef08',\n",
       " 'value': {'animal_preference': 'I like cats'},\n",
       " 'created_at': '2025-06-27T21:00:09.131605+00:00',\n",
       " 'updated_at': '2025-06-27T21:00:09.131605+00:00'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = in_memory_store.get(namespace_for_memory, key)\n",
    "memory.dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbot with Memory\n",
    "- Providing both short term and long term memory to chatbot - `Checkpointer` and `Store`\n",
    "- thread_id and user_id - both are required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model=\"gpt-4o\",temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.graph.message import MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.store.base import BaseStore\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "\n",
    "# Chatbot Instructions\n",
    "MODEL_SYSTEM_MESSAGE = \"\"\" \n",
    "You are a helpful assistant with memory that provides information about the user. \n",
    "If you have memory for this user, use it to personalize your responses.\n",
    "Here is the memory (it may be empty): {memory}\"\"\"\n",
    "\n",
    "# Create new memory from the chat history and any existing memory\n",
    "CREATE_MEMORY_INSTRUCTION = \"\"\"\"You are collecting information about the user to personalize your responses.\n",
    "\n",
    "CURRENT USER INFORMATION:\n",
    "{memory}\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Review the chat history below carefully\n",
    "2. Identify new information about the user, such as:\n",
    "   - Personal details (name, location)\n",
    "   - Preferences (likes, dislikes)\n",
    "   - Interests and hobbies\n",
    "   - Past experiences\n",
    "   - Goals or future plans\n",
    "3. Merge any new information with existing memory\n",
    "4. Format the memory as a clear, bulleted list\n",
    "5. If new information conflicts with existing memory, keep the most recent version\n",
    "\n",
    "Remember: Only include factual information directly stated by the user. Do not make assumptions or inferences.\n",
    "\n",
    "Based on the chat history below, please update the user information:\"\"\"\n",
    "\n",
    "def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Load memory from the store and use it to personalize the chatbot's response.\"\"\"\n",
    "\n",
    "    # Get user id\n",
    "    user_id = config['configurable']['user_id']\n",
    "\n",
    "    # Get the memory\n",
    "    namespace = ('memory',user_id)\n",
    "    key = \"user_memory\"\n",
    "    existing_memory = store.get(namespace,key)\n",
    "\n",
    "    # Extract the actual memory content if it exists\n",
    "    if existing_memory:\n",
    "        # Value is a dictionary with a memory key\n",
    "        existing_memory_content = existing_memory.value.get('memory')\n",
    "    else:\n",
    "        existing_memory_content = \"No existing memory found.\"\n",
    "    \n",
    "    # Format the system prompt\n",
    "    system_message = MODEL_SYSTEM_MESSAGE.format(memory=existing_memory_content)\n",
    "\n",
    "    # generate response from the llm\n",
    "    return {'messages': model.invoke([SystemMessage(content=system_message)] + state['messages'])}\n",
    "\n",
    "\n",
    "def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"Reflect on the chat history and existing memory to write new memory to the store\"\n",
    "\n",
    "    # Get the user_id\n",
    "    user_id = config['configurable']['user_id']\n",
    "\n",
    "    # Get the memory\n",
    "    namespace = ('memory', user_id)\n",
    "    key = 'user_memory'\n",
    "    existing_memory = store.get(namespace, key)\n",
    "\n",
    "    # In case there is no memory# Extract the memory\n",
    "    if existing_memory:\n",
    "        existing_memory_content = existing_memory.value.get('memory')\n",
    "    else:\n",
    "        existing_memory_content = \"No existing memory found.\"\n",
    "\n",
    "    # Format the prompt\n",
    "    system_message = CREATE_MEMORY_INSTRUCTION.format(memory=existing_memory_content)\n",
    "    new_memory = model.invoke([SystemMessage(content=system_message)]+state['messages'])\n",
    "    # Update the existing memory\n",
    "    key = 'user_memory'\n",
    "\n",
    "    # Write value as a dictionary\n",
    "    value = {\"memory\":new_memory.content}\n",
    "\n",
    "    # Put the new memory\n",
    "    store.put(namespace,key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCAFNAJIDASIAAhEBAxEB/8QAHQABAAMBAQEBAQEAAAAAAAAAAAUGBwQIAwIBCf/EAFQQAAEEAQICAwkJDAcFCQEAAAEAAgMEBQYRBxITITEIFBUXIkFVVpQWN1FhhJPR09QjMjZScXR1gZWytNIzNEKSsbPCCYKRocEkJTVFRmJjcoaW/8QAGwEBAQEAAwEBAAAAAAAAAAAAAAECAwQFBgf/xAA0EQACAAMFBQYFBQEBAAAAAAAAAQIDERIhMVGRBBRScdETMkFhYpIFFSOBoSIzU7HB4fD/2gAMAwEAAhEDEQA/AP8AVNERAERcuTyVbD0J7tuToq8DS97tiTt8AA6yT2ADrJIAVSbdEDqXBZz2MpyGOxkakEgOxbJO1pH6iVX26fu6xDbOfknp0HdcWErymMbeY2HtO73fCwHkHYefbmUpV0Rp2jEI6+BxkDANg2OnGP8AouxYlwXRRVfl1/5TzNUSxPv7qsL6Yoe0s+lPdVhfTFD2ln0p7lcL6HoezM+hPcrhfQ9D2Zn0KfR8/wAC4e6rC+mKHtLPpT3VYX0xQ9pZ9Ke5XC+h6HszPoT3K4X0PQ9mZ9CfR8/wLh7qsL6Yoe0s+lPdVhfTFD2ln0p7lcL6HoezM+hPcrhfQ9D2Zn0J9Hz/AALj+s1Nh5HBrMtRc49gFlhP+KkmuD2hzSHNI3BB6iFFSaRwUrS1+Fx72ntDqsZH+CiX6Ar4mQ2tMy+ALQ8o14RvTm+KSD70b/jM5XfH5ksyYrlE1zV346MXFsRROn86czDPHPAaWRqv6K1ULubo3bbgtdsOZjh1tdsNx2gEECWXDFC4HZZkIiLICIiAIiIAqzm3Nymr8Lin7mCGOTJyt8znRuYyJp+Ec0hf+WJqsyqmRk7w4l4aR42ivY+zVa//AOVj45Gt/W3pT/uFdiQv1POj/oqLWiIuuQKi6x43aL0FlZsbmsw6C5XgbZtMr057LakLiQ2Sd0THNhadjs6QtB2V6XmjjNVuYjX+o8npmtrzTurLFODoLuDxJyuJzjmRubHHYj5HxxFpcWEvdEeUbh2yA0qlx8wNvidn9IuitwwYfE18rLmnVJ+8yyQTOdvL0XRtY2OJrhIX8ry9zW7mNyktJccdFa4yDqOHy8k1rvZ12OOxRsVu+IG8vNLCZY2iZg52+VHzDyh8IWN5J/EHT+rdcX6em7Uer8/oHHjGyUabpqEWTrx3HSwGXYxsIfIzka87O3aOtQWJw80XFHhrm8dh+Il6hDUyGPyeS1LHkpXMtz12iNorS7thjDmEOljjZDu5g5iAeUDUM13W2iK+L09kcGcnqalmMhVpMnx+IvPY1szS/mBbA7neGtP3Fvl7gjYEHbamPEjGuG4DhuOYEH/gexeV6emczpzuaOAz5NOZZ9jTeSxN/KYyrj5ZLsEbIpGynvdrekLg6QEtA37epep4ZBNEyQNc0PaHAPaWuG/wg9h+JAftERAVnPObiNV4LIM3Hfr3YuwB2OaWPlicfhLXMc0fB0rlZlVNYyd85/SWOYOaWTIOtPG/3sUULyXf33RN/wB8K1rsTO5A3l/rK8EERF1yBERAEREAUNqvT3ujxYhim70vQSts07XLzdDMzra7bzjta4edrnDzqZRahicESihxQwK7pzVbMy+TGZCLwZnoGf8AaKDn9ZHZ0kTv7cZ8zh2dh2IIFc8ROn/TGs//AO1y/wBqV1zGAx2fiZHkKcVoRnmjc8eXG78Zjh1tPxggqG9wfQnapqLPU4/xBd6fb9czXu/5rnalRuqdnyxWuP4+5q5kGOBOn9v/ABjWZ/8A2mX+1K74XEQ4HFVsfXltTQV28jZLtqW1M4b/ANqWVznvPxuJKhPcVb9bc9/fr/Up7irfrbnv79f6lTs5fGtH0JRZlpRVb3FW/W3Pf36/1KqfCqnl9a6BxeZv6rzLLdnpecQGBrPJlewbAxHzNHnTs5fGtH0FFmaqs8k4G4CWR7zl9ZAuJJDdZ5do/UBZ2H5Apr3FW/W3Pf36/wBSnuKt+tue/v1/qU7OXxrR9BRZkGOBGnx/5xrQ/l1rl/tSsEbsPwx03DXlvXX1WPLYfCF2e/bne5xIY18rnyyOJOwbuerqGwC+Z0PO/ql1Tn5WedvTxM3/AFsiBH6iu/EaOxOFsi1DXdNeDS3v25M+xPse0CSQucAfgBA+JLMqG9xV5dX0YuOHS+Ku2cna1FmIe98hajEFemSHGnWB3DCRuC9x8p5B23DWjcMBNoRFxxxuZFVhuoREXGQIiIAiIgCIiAIiIAiIgCzrufPegwHyj+IkWirOu5896DAfKP4iRAaKiIgCIiAIiIAiIgCIiAIiIAiIgCIiAIiIAs67nz3oMB8o/iJFoqzrufPegwHyj+IkQGioiIAiIgCIiAIiIAiIgCIiAIq/qXVRwtqnQqUzkcpbD3xQdJ0bGMbtzSSP2PK0FzR1Aklw2B69onw/rD0ZhB8um+pXZg2eZHCorqPNpFoXZFSfD2sPRmD9um+pTw9rD0Zg/bpvqVvdZma1RaF2RUnw9rD0Zg/bpvqU8Paw9GYP26b6lN1mZrVChC90dxlu8BOGdjWNXTMmqYKliOO3WjtisYIX7jpebkfuA/kbtt/b336ljXcId0lb4y4m3puLR8mLxmn67pJsw6+JWyTSzOcyIR9G3Ylped+Y/ednX1bXqeLUGsdOZPB5XC4KzjcjWkq2Ijem8pj2lp2+49R2PUfMVRO544RZbudeH7dMYiph7zn2ZLVm9NblY+d7jsNwIjsGtDWgb+YnzlN1mZrVCh6FRUnw9rD0Zg/bpvqU8Paw9GYP26b6lN1mZrVChdkVJ8Paw9GYP26b6lPD2sPRmD9um+pTdZma1QoXZFSfD2sPRmD9um+pXTjNZXY8tTx2cx0NKS4XMrWqdgzQvkDS4xu5mNLHFrXEdRB5T177BZezTEm7n90ShbURF1SBERAEREBR8r18S/yYgbfF92O/+AUqorKe+Wf0Q3/OcpVes+7ByRphERYMhFE5rVeK07kMNSyFrve1mLRpUY+je7pphG+Ut3aCG+RG87u2HVtvuQE0pqvFa3wFXNYW137jLPOIp+jfHzcr3Md5LwCNnNcOseZQEsiIqAiIgCKI0nqvFa507RzuEtd+4q6wyV7HRvj527kb8rwHDrB7QF/crqvFYTNYTE3bXQ5DNSywUIeje7pnxxOleNwCG7MY4+URvtsOvqUBLKB1Udp9PEdoy9br/WR/gVPKB1V/Taf/AEvW/eK5pXfRqHE0FEReOZCIiAIiICj5T3yz+iG/5zlKqKynvln9EN/znKVXrPuwckaZkXE+a7qXi3o3Q7stksLg7+NyGSsyYq2+pYtSwOrsjibMwh7Q0TOeQ0jfZu/VuDUdTsyNnKad0BhdUZzWWXgjyFuaSDP+CWNrMnZG1ty3Ax8zpInPbGAwbuIcXhbLrjhvp7iNXpxZ6i+y6nKZq1ivamqzwOI2JZNC9j27jqIDtj591Cy8BdDPpYerFhX0WYlksdSXH3rFSZrJXc0rXSxSNfIHu8pwe5wcdydyVwtMyYbo7U+W1RT4QOzVzwhdx/EHK4wWe+TZMkcNe+yP7sWMMuzQB0ha0uADiASVrPcqe8Lpn/7W/wCLmVgw/BLReAuVrOOwxqOq5J2Xrwx25+ggtOjfE6SOLn5GbskeC1rQ0k77bgFccWM1Jw7q18BobRuEs6cqtJgde1FPXkDnuc945TVmO3M4ncvPb2BRKmIIjjzLkJs9wvxdHMZHDQZTUbqlx+OsOhfNB3jac6MkHsJaNj2tIDm7OaCMg1J4a05oXjVl62r9Sum0PlXNwUcuYsPEDRBWsFspc8my0mUs2nMmzezYklehMZhMnrK3j7uttM4zG3MJbF3FOx2ZmuBspikjc928MIGzJHAAh4PMT1EBdWR4U6WyuI1Ti7WL6WjqiYz5eLviUd8vMbIydw7dnkRMGzC0eTv2kkmqgyvIwX+I2oeLs93VGcwJ0tK2ji4cVkpKcdUClHY74kYxwEpc+V39IHN5WAAdpUXwq1LmuN+oDZz+cyeBON0lhMlBXxVx1SM2bkUsk1mRjTtKAY2hrJA5gAO7dzutc1XwS0ZrbM2cpl8TJNctQtr2zXvWK8dyJu/KyxHFI1kzRuQBIHdXV2L6al4M6O1dka9/I4g99Q1Bj+anamqCWqDv3vK2F7RLDvv9zeHN6z1dZSjB5Z4carzM2jODOmIauqclhJdN3MrZq6PtR1LNyVtlkbA6V00LmxMEjnEMeCS9m4IHVedNX9U3NdcIo9VU8lUmq6ozcFA5h8LrktLwZO6EzGJ7mF4Diwnfc9Hues7rbfEzo9umcRgYsS+rj8Q17ce6pcngsVA/fnEdhjxK3m32Oz+sbA9gX1w3CPSWnxgPB+HbWOCsT26DhPKXRzTseyaRxLiZHObI8Eycx69+0AqKFguCgdVf02n/ANL1v3ip5QOqv6bT/wCl637xXald9GocTQURF45kIiIAiIgKPlPfLP6Ib/nOUqvhqjBXnZmpm8YxlmeGB9aem9wYZoy4OBa49Qe0g7A9RDj1jqKi/DObH/orNH8lih9pXrQ0mQQtNXLxaX9msSbRQnhnN+pWb+fofaU8M5v1Kzfz9D7Sr2fqXuh6ihNooTwzm/UrN/P0PtKeGc36lZv5+h9pTs/UvdD1FCbRQnhnN+pWb+fofaVHae11c1Vh6+Uxekc3aoT83Ry9JSZzcri09TrII62kdYTs/UvdD1FC2IoTwzm/UrN/P0PtKeGc36lZv5+h9pTs/UvdD1FCbRQnhnN+pWb+fofaU8M5v1Kzfz9D7SnZ+pe6HqKE2oHVX9Np/wDS9b94r9+Gc36lZv5+h9pX1p4jK6kyuNsX8e/C4+hN3z0FiWOSeeQNcGAiNzmtaC7m35iSQBsO1ahpLdqKJXeaf9MJUvLyiIvGMhERAEREAREQBERAEREAWddz570GA+UfxEi0VZ13PnvQYD5R/ESIDRUREAREQBERAEREAREQBERAEREAREQBERAFnXc+e9BgPlH8RItFWddz570GA+UfxEiA0VERAEREAREQBERAEREARFD5jWWn9PTthyucxuMmcNxHctxxOI+HZxC1DBFG6QqrGJMIqv409F+t+B/acP8AMnjT0X634H9pw/zLm3edwPRmrLyLQiq/jT0X634H9pw/zJ409F+t+B/acP8AMm7zuB6MWXkWhFV/Gnov1vwP7Th/mTxp6L9b8D+04f5k3edwPRiy8i0LOu5896DAfKP4iRUrumMboPjxwbz2lXat094QfH3zjZX5OAdFbjBMZ35+oHrYT8D3LC/9nNoPTXCbRmW1XqfNYjF6ozUhrR1bt2KKatUjd2FrnAtMjxzbEdjGEdqbvO4HoxZeR7uRVfxp6L9b8D+04f5k8aei/W/A/tOH+ZN3ncD0YsvItCKr+NPRfrfgf2nD/MnjT0X634H9pw/zJu87gejFl5FoRVfxp6L9b8D+04f5k8aei/W/A/tOH+ZN3ncD0YsvItCKu1OI+k8hYZXq6owtmd52ZFDkIXucfgADtyrEuKOXHLujTXMlGsQiIsEOLNXXY3DX7bAHPr15JWg9hLWk/wDRU7R2Pjp6fpSgc9qzCyezZcPLnlc0Fz3Hzkk/q6gOoBWjVn4K5n8ym/cKgdOfg9i/zWL9wL0ZF0l08Wa8CRREWjIREQBERAEREAREQBERAEREB8rNWG7A+CxDHPC8cr45WhzXD4CD2r58N55DhblN73SR4+9PUhc87kRNduxu/n5WuDR8TQulcfDf+rZ79L2P9KR3yYvsXwLeiIvMIROrPwVzP5lN+4VA6c/B7F/msX7gU9qz8Fcz+ZTfuFQOnPwexf5rF+4F6Mn9l8/8NeB+tQZhmnsDksrJXntx0a0tp1eq0OllDGFxawEgFx22AJA3I6wqZDxx03Y1LofCRC3JY1hROQx8zY29EyPoTMwSu5vJc9jX8oAdv0busbDfQXND2lrgC0jYg+deU8RwV17pzSecuVsPHZ1FpvI0Kuk6zrcO1rHUrMrozzF+0fSQ2pmEPIILRuNtlG2sDJqlXukMFks9Sw+OwWfyV2866Kgq1onNnZVtd7SyAmUAM5t3Bztt2t/GLWmu47j1k487pDFY/F5bVMGbz+Yx9i5PDTryRMqunBjjaJ2N2YWNPM4EujYe2Q7Lu4b8JMtofXmg5TW6TGYfRE+IuXulYS68+zVkdu3fmJeY5n8wG3x9Y3rWB4Zay0ta0Tl26efkJcRq3P3bNGG5XbJ3pdksiKdrnPDCAJGOLebm2PZuNlP1A0M90Jp8XrbjjsyNP1Ml4Im1MazBjmWukERZzc/SFolPRmQR9GHdrlp68oxdzpksZRn0pcwOpNR46zlp5e+4NZTU8QKktp0wMlXpuZsjQ87sZC5rnM5ubdy9XKwt+IMz1Zx3xultRagwsens/m7uBoxZK94MghcyOs9sjukDpJWA8vRO3Z9+dxytds7b6aY474PVGZw9OPHZbH083Ulu4jK34GR1shFG1r5DH5Zkbs14cOkYzmAJbuOtRVrQmdk15xeyLaO9PPafx9HHS9NH93mjjuB7dubduxmj63AA83UTsdoNvCXP38bwWx9qka8OEwFrG5iRs0ZNR8mNZAANneX5YI3ZuOrffbrUqwWzS/dAYHVFnCuZi81jsRnZzXw+ayFVsdTIyBrnNEezy9vO1jnMMjGB4Hk7nqUQzuo9POo0si7T2pWYa3kpMMzJ95xPi79bLJGIAxspkcXuj2a5jHM3c0FwduBQ+HvAnK4SxoTC5nTuo7409LXlmy1rWU0mIY+u37lLWqGVziSWt2jdExrQ4gHYKaxHCnVNXhLofDS4vlyWN1z4YtQd8RHo6nhaex0nNzbH7k9juUEu69ttwQpWIF+h474KHCanv5ehlNPWdOyQxX8ZfijfZD5mtMDWCGSRkhkL2taGuPlHY7Fctnug8TiaOpJM3p/PafvYPEPzsmNvwwdPZps35pITHM5jtiACC9pBc3cDdU/iBwi1RqLPcS8hj6cXS2rmAymHE9hjY7slFwkkidsSWAlvLu4AbuB6wCuDiVoLWvF4atzL9KTaflGishgMbi7t6s+xbtWSxziXRSOjYxvRNaC54JLySG7K1YNR0rxnxuqdTY/C+B8ziJcnSmyGOsZSCOKK7DE6MPMe0heDtMx3K5rTyknbqVi0ZrOhrvGWcjjWTCnDes0GyzNAEzoJnQvezYndnOxwB6t9uxZV3Qkd3T+gtJZbCy1oddYW9VjxFSZ45rUs471kgAG5ILJXO6gQDGCepu41TQOj6ugNFYTTlNxkgxtSOt0rvvpXAeVI7/3Odu4/G4rSbrQE+uPhv/Vs9+l7H+ldi4+G/wDVs9+l7H+laj/Zj+xVgW9EReYQidWfgrmfzKb9wqB05+D2L/NYv3ArNnKb8jhMhUj2Ek9eSJu/wuaQP8VT9F5GHJaYxz4j5cULYJoj99DKwBr43DzOaQQQvRkXyXz/AMNeBNoiLRkIiIAqDJ3P/DGaR0j+HmlnvcS5znYeuSSe0nyFfkUpUHFhsLj9O4yvjcVRr43H128kNWpE2KKNvbs1rQAB1+ZdqIqAiIgCIiAjLemMNfzdPM2cTRsZikx0dbIS1mOsQNd981khHM0HzgEbqTREAXHw3/q2e/S9j/SuqWVkET5JHtjjYC5z3HYNA7SSuXhiOnwdy+0HvfIX57VdxG3PEXcrHj4nBvMPhDgkd0mJ8i+Bb0RF5hAoHKaC05m7r7l7B0LVt4AfPJXaZH7dm7ttzt8ankW4I4pbrA6PyLWhVvFbpH1dx/zITxW6R9Xcf8yFaUXLvM7jerLaeZVvFbpH1dx/zITxW6R9Xcf8yFaUTeZ3G9WLTzKt4rdI+ruP+ZCeK3SPq7j/AJkK0om8zuN6sWnmVbxW6R9Xcf8AMhUXghoLTub4X4W7kMPUuW5em55pow5ztp5ANyfiAH6lsazrufPegwHyj+IkTeZ3G9WLTzJzxW6R9Xcf8yE8VukfV3H/ADIVpRN5ncb1YtPMq3it0j6u4/5kJ4rdI+ruP+ZCtKJvM7jerFp5lW8VukfV3H/MhPFbpH1dx/zIVpRN5ncb1YtPMq7OF+kWPa73N41xadwH1muG/wCQjZWcANAAGwHYAv6i445kczvxN8yNt4hERcZAiIgCIiAIiIAiIgCzrufPegwHyj+IkWirOu5896DAfKP4iRAaKiIgCIiAIiIAiIgCIiAIiIAiIgCIiAIiIAs67nz3oMB8o/iJFwd0zrrWnDLhBl9U6GoY3J5TFFtmxVykMsrH1Rv0paI3sPM3cO3322a7q7NsQ/2eXGTX/FvTWVjzWNw1LSGFBrVLFOvMyxPae8yOBc6VzS1rXHcBoPls6+o7gew0REAREQBERAEREAREQBERAERROq9QRaV03kctKzpG1IXSNj32MjuxrAfhc4gfrWoYXHEoYcWCE13xMoaKLKrYnZLMSt546ELw0hv48jj943cbb7Enr2B2O2W3OKWsr7y8ZGpjGnsip1A/YfG6Qu3Px7D8irLDYnnsXLsvfORtv6azOf7bz8HwNA2AHmAAX7X3+zfDNnkQpRwqKLxbv0QbpgTXjA1n6zS+xV/q08YGs/WaX2Kv9WoVF3t12f8Ajh9q6EtMlLetdWX6k1WzqF09eZjo5YpKNYte0jYtI6PrBB2Ve4c1r/CbStfTmlcmcViIHvkZAyrC88z3FziXOYSTufOewAdgC7UTddn/AI4faugtMmvGBrP1ml9ir/Vp4wNZ+s0vsVf6tUy7qupQ1Zi9PyRzG7ka09qKRrR0bWwmMODjvuCelbtsD2Hs88ysrZtmdUpcN3pXQWmT0PEjWdd4cM9HY26+SzRiLT+XkDT/AM1edF8Z48ncgxuoa8WMuzOEcNuF5Nad57G9fXG4+YO3B7A4kgLKF87NeO3BJDMwSRSAtc09hC4J3w7Zp8Nmwk80qFtZnqpFQeDeqZ89pyaleldPkMXIK75nu3fNGRvG93x7btJPaWOPnV+XwE+TFs8yKVHiisIiLgIEREAREQBUHji4t4d2ezo+/KYfv8HfMW3/AD2V+URq7TsWrdM5LETP6NtuExtlA3Mb+1rwPha4A/qXZ2WYpU+CZFgmn+SrE84IvwxlmtLNTvwmtkaruiswH+y8ecfC09oPnBBVczFPWUuSmdisvgqtA7dFFcxc00reob8z22WA9e5GzR1bDr7V+mOKiqlXkYpQsyybj2b1ifRdCOnDkcXcyro7dO1cdUgsuEEjoopZA13kl435S0hxa0edWYY/iH1757THxf8Aclj7WpTF4jLXaNypqqbD5mvNsGw1ce+KMt69w9sksgd5tuzs864JiinQuCjVeXUGD5LFXW425jbLcdjMU/VmFjgxOGyps+DnOmY2ZgcGMMW/kuDQBsXO22XZxErs0Db4j0NNxDC492nKFqSGg3o2xl1maKaVob967ogd3DrPKCesbrdaekMFj8fDQq4THVqMMzbMVaGpGyKOVpBbI1oGwcCAQ4dYIC634ihLbntPpV32Z4RXlmdE0vkiBJEbnbbloLneSeryj8K6+6OmN+evUGQ0sPpvAceNJUtOsrVofAN2Z9Wm/wC5BrnwckgaDtu8A7u7XcoJ3W0qsnQ2OwlNz9LYjBYPKM5ugsHGNLI+ct6TdsZjceYMAOzh1taTvtsuI4/iHt1Z7TO/6Esfa1zy4YpVVZxdbsMEvLIhc0VOZQ4gh7efO6aLN+sNwtgEj8vfat088dWF8srgyNg3c4+YLsQxOLwoU0LgS4+6fUrW7cvelMv/AC89jl/1LZ1n/BrSdjT+np71+F1fI5WUWHwvGzoYgOWKN3xgbuI8xe4eZaAvz34nNhm7XHFBhctEkbYREXmECIiAIiIAiIgKprXh1jtaCOaRz6WSibyxXoAOfl7eR4PU9u/mPZ17EE7rNcnwf1PSe7vTwfk4h964TOge7/cLSB/fK3VF6ez/ABHaNmhsQOqyZTz14s9Zehq/tzPoTxZ6y9DV/bmfQvQqLvfPNp4YdH1F2R568WesvQ1f25n0J4s9Zehq/tzPoXoVE+ebTww6PqLsjz14s9Zehq/tzPoTxZ6y9DV/bmfQvQqJ882nhh0fUXZGA1OFOr7T9pKVCoPxp7pP/AMY7/or3pLg9Swl+LIZSz4WuQkOhjMfJBC78YN3Jc4eZzj1doAK0NF1Z/xXaZ8Lhbonl/6o5BEReQQIiIAiIgP/2Q==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_node(\"write_memory\", write_memory)\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_edge(\"call_model\", \"write_memory\")\n",
    "builder.add_edge(\"write_memory\", END)\n",
    "\n",
    "# Store for long-term (across-thread) memory\n",
    "across_thread_memory = InMemoryStore()\n",
    "\n",
    "# Checkpointer for short-term (within-thread) memory\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# Compile the graph with the checkpointer fir and store\n",
    "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hey! My name is Manan.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello, Manan! It's great to meet you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# Thread_id and Config_id\n",
    "config = {'configurable':{'thread_id':\"thread_1\", \"user_id\":\"user_1\"}}\n",
    "# Input message\n",
    "message = HumanMessage(content=\"Hey! My name is Manan.\")\n",
    "\n",
    "for event in graph.stream({'messages':[message]}, config, stream_mode='values'):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I like to use Langgraph.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's great to hear, Manan! Langgraph is a powerful tool for language analysis and visualization. What do you enjoy most about using it, or is there something specific you'd like to know or discuss about Langgraph?\n"
     ]
    }
   ],
   "source": [
    "# User input \n",
    "input_messages = [HumanMessage(content=\"I like to use Langgraph.\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hey! My name is Manan.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello, Manan! It's great to meet you. How can I assist you today?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I like to use Langgraph.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's great to hear, Manan! Langgraph is a powerful tool for language analysis and visualization. What do you enjoy most about using it, or is there something specific you'd like to know or discuss about Langgraph?\n"
     ]
    }
   ],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"thread_1\"}}\n",
    "# get the state for the thread\n",
    "state = graph.get_state(thread).values\n",
    "\n",
    "for m in state['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': ['memory', 'user_1'],\n",
       " 'key': 'user_memory',\n",
       " 'value': {'memory': \"**Updated User Information:**\\n- User's name is Manan.\\n- Likes to use Langgraph.\"},\n",
       " 'created_at': '2025-06-27T21:00:49.915718+00:00',\n",
       " 'updated_at': '2025-06-27T21:00:49.915718+00:00'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 'user_1'\n",
    "namespace = ('memory',user_id)\n",
    "key = 'user_memory'\n",
    "\n",
    "memory = across_thread_memory.get(namespace,key)\n",
    "memory.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
