{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot with Profile Schema\n",
    "- We saved the memory as a string\n",
    "- It is beneficial if the memory has some form of structure\n",
    "\n",
    "## Goals\n",
    "- Create a chatbot with both `within-`thread and `cross-thread` memory saving semantic memory **\"in the hotpath\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model=\"gpt-4o\",temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a User Profile Schema\n",
    "- For structured data, we can use Pydantic, TypedDict, JSON etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "\n",
    "class UserProfile(TypedDict):\n",
    "    username: str\n",
    "    interests: List[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving a Schema to the Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'username': 'Manan', 'interests': ['Reading', 'Coding']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of UserProfile\n",
    "user_1 = UserProfile(username=\"Manan\", interests=[\"Reading\",\"Coding\"])\n",
    "user_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': ['1', 'memory'],\n",
       " 'key': 'a0bd8346-412e-4727-98c5-1cae8b3246c3',\n",
       " 'value': {'username': 'Manan', 'interests': ['Reading', 'Coding']},\n",
       " 'created_at': '2025-06-29T18:39:26.466977+00:00',\n",
       " 'updated_at': '2025-06-29T18:39:26.466977+00:00',\n",
       " 'score': None}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the UserProfile as the value in the store \n",
    "from uuid import uuid4\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "# Initalize the memory store\n",
    "in_memory_store = InMemoryStore()\n",
    "\n",
    "# Namespace\n",
    "user_id = \"1\"\n",
    "namespace_for_memory = (user_id, \"memory\")\n",
    "\n",
    "# Key-Value pair\n",
    "key = str(uuid4())\n",
    "value = user_1\n",
    "\n",
    "in_memory_store.put(namespace_for_memory,key,value)\n",
    "memory = in_memory_store.search(namespace_for_memory)\n",
    "memory[0].dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbot with Profile Schema\n",
    "- We have now defined the structure of the memory for a User\n",
    "- Now, using with_structured_output, we can get the strucred response from the llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'username': 'Manan', 'interests': ['Reading Books']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o\",temperature=0)\n",
    "structured_model = model.with_structured_output(UserProfile)\n",
    "structured_model.invoke(\"My name is Manan. I like to Read Books!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's modify our chatbot\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.store.memory import InMemoryStore, BaseStore\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "## Write the prompts\n",
    "# Chatbot instruction\n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"You are a helpful assistant with memory that provides information about the user. \n",
    "If you have memory for this user, use it to personalize your responses.\n",
    "Here is the memory (it may be empty): {memory}\"\"\"\n",
    "\n",
    "# Create new memory from the chat history and any existing memory\n",
    "CREATE_MEMORY_INSTRUCTION = \"\"\"Create or update a user profile memory based on the user's chat history. \n",
    "This will be saved for long-term memory. If there is an existing memory, simply update it. \n",
    "Here is the existing memory (it may be empty): {memory}\"\"\"\n",
    "\n",
    "# node 1 - The Chatbot\n",
    "def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    # Get the memory\n",
    "    user_id = config['configurable']['user_id']\n",
    "    namespace = ('memory',user_id)\n",
    "    key = 'user_memory'\n",
    "\n",
    "    existing_memory = store.get(namespace,key)\n",
    "    if existing_memory and existing_memory.value:\n",
    "        memory_dict = existing_memory.value\n",
    "        formatted_memory = (\n",
    "            f\"Name: {memory_dict.get('username','Unknown')}\\n\"\n",
    "            f\"Interests: {''.join(memory_dict.get('interests',[]))}\"\n",
    "        )\n",
    "    else:\n",
    "        formatted_memory = None\n",
    "    \n",
    "    # Modify the system prompt\n",
    "    system_message = MODEL_SYSTEM_MESSAGE.format(memory=formatted_memory)\n",
    "    # Get the response\n",
    "    return {'messages':model.invoke([SystemMessage(content=system_message)] + state['messages'])}\n",
    "\n",
    "def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Reflect on the chat history and save a memory to the store.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve existing memory from the store\n",
    "    namespace = (\"memory\", user_id)\n",
    "    existing_memory = store.get(namespace, \"user_memory\")\n",
    "\n",
    "    # Format the memories for the system prompt\n",
    "    if existing_memory and existing_memory.value:\n",
    "        memory_dict = existing_memory.value\n",
    "        formatted_memory = (\n",
    "            f\"Name: {memory_dict.get('user_name', 'Unknown')}\\n\"\n",
    "            f\"Interests: {', '.join(memory_dict.get('interests', []))}\"\n",
    "        )\n",
    "    else:\n",
    "        formatted_memory = None\n",
    "        \n",
    "    # Format the existing memory in the instruction\n",
    "    system_msg = CREATE_MEMORY_INSTRUCTION.format(memory=formatted_memory)\n",
    "\n",
    "    # Invoke the model to produce structured output that matches the schema\n",
    "    new_memory = structured_model.invoke([SystemMessage(content=system_msg)]+state['messages'])\n",
    "\n",
    "    # Overwrite the existing use profile memory\n",
    "    key = \"user_memory\"\n",
    "    store.put(namespace, key, new_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the graph\n",
    "from IPython.display import display, Image\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_node(\"write_memory\", write_memory)\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_edge(\"call_model\", \"write_memory\")\n",
    "builder.add_edge(\"write_memory\", END)\n",
    "\n",
    "# Store for long-term (across-thread) memory\n",
    "across_thread_memory = InMemoryStore()\n",
    "\n",
    "# Checkpointer for short-term (within-thread) memory\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# Compile the graph with the checkpointer fir and store\n",
    "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, my name is Manan and I like to Read Books and Code.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Manan! It's great to meet you. Reading books and coding are both fantastic hobbies. Do you have any favorite books or programming languages you enjoy working with?\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input \n",
    "input_messages = [HumanMessage(content=\"Hi, my name is Manan and I like to Read Books and Code.\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, my name is Manan and I like to Read Books and Code.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Manan! It's great to meet you. Reading books and coding are both fantastic hobbies. Do you have any favorite books or programming languages you enjoy working with?\n"
     ]
    }
   ],
   "source": [
    "# Check the within-thread memory\n",
    "thread = {'configurable':{'thread_id':\"1\"}}\n",
    "state = graph.get_state(thread)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': ['memory', '1'],\n",
       " 'key': 'user_memory',\n",
       " 'value': {'username': 'Manan', 'interests': ['Reading Books', 'Coding']},\n",
       " 'created_at': '2025-06-28T17:08:41.320754+00:00',\n",
       " 'updated_at': '2025-06-28T17:08:41.320754+00:00'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the cross-thread memory\n",
    "namespace = ('memory', \"1\")\n",
    "key = 'user_memory'\n",
    "memory = across_thread_memory.get(namespace,key)\n",
    "memory.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "My full name is Manan Parakh. I like to play Cricket as well!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Nice to meet you, Manan Parakh! It's great to hear that you enjoy playing cricket along with reading and coding. Do you have a favorite cricket player or team? And are there any particular genres of books or coding projects you're currently interested in?\n"
     ]
    }
   ],
   "source": [
    "# User input 2\n",
    "input_messages = [HumanMessage(content=\"My full name is Manan Parakh. I like to play Cricket as well!\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, my name is Manan and I like to Read Books and Code.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Manan! It's great to meet you. Reading books and coding are both fantastic hobbies. Do you have any favorite books or programming languages you enjoy working with?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "My full name is Manan Parakh. I like to play Cricket as well!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Nice to meet you, Manan Parakh! It's great to hear that you enjoy playing cricket along with reading and coding. Do you have a favorite cricket player or team? And are there any particular genres of books or coding projects you're currently interested in?\n"
     ]
    }
   ],
   "source": [
    "# Check the within-thread memory\n",
    "thread = {'configurable':{'thread_id':\"1\"}}\n",
    "state = graph.get_state(thread)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': ['memory', '1'],\n",
       " 'key': 'user_memory',\n",
       " 'value': {'username': 'Manan Parakh',\n",
       "  'interests': ['Reading Books', 'Coding', 'Cricket']},\n",
       " 'created_at': '2025-06-28T17:11:53.118488+00:00',\n",
       " 'updated_at': '2025-06-28T17:11:53.118488+00:00'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the cross-thread memory\n",
    "namespace = ('memory', \"1\")\n",
    "key = 'user_memory'\n",
    "memory = across_thread_memory.get(namespace,key)\n",
    "memory.dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex Schemas: `with_structured_output` Fails!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class OutputFormat(BaseModel):\n",
    "    preference: str\n",
    "    sentence_preference_revealed: str\n",
    "\n",
    "class TelegramPreferences(BaseModel):\n",
    "    preferred_encoding: Optional[List[OutputFormat]] = None\n",
    "    favorite_telegram_operators: Optional[List[OutputFormat]] = None\n",
    "    preferred_telegram_paper: Optional[List[OutputFormat]] = None\n",
    "\n",
    "class MorseCode(BaseModel):\n",
    "    preferred_key_type: Optional[List[OutputFormat]] = None\n",
    "    favorite_morse_abbreviations: Optional[List[OutputFormat]] = None\n",
    "\n",
    "class Semaphore(BaseModel):\n",
    "    preferred_flag_color: Optional[List[OutputFormat]] = None\n",
    "    semaphore_skill_level: Optional[List[OutputFormat]] = None\n",
    "\n",
    "class TrustFallPreferences(BaseModel):\n",
    "    preferred_fall_height: Optional[List[OutputFormat]] = None\n",
    "    trust_level: Optional[List[OutputFormat]] = None\n",
    "    preferred_catching_technique: Optional[List[OutputFormat]] = None\n",
    "\n",
    "class CommunicationPreferences(BaseModel):\n",
    "    telegram: TelegramPreferences\n",
    "    morse_code: MorseCode\n",
    "    semaphore: Semaphore\n",
    "\n",
    "class UserPreferences(BaseModel):\n",
    "    communication_preferences: CommunicationPreferences\n",
    "    trust_fall_preferences: TrustFallPreferences\n",
    "\n",
    "class TelegramAndTrustFallPreferences(BaseModel):\n",
    "    pertinent_user_preferences: UserPreferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 validation error for TelegramAndTrustFallPreferences\n",
      "pertinent_user_preferences.communication_preferences.semaphore\n",
      "  Input should be a valid dictionary or instance of Semaphore [type=model_type, input_value=None, input_type=NoneType]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/model_type\n"
     ]
    }
   ],
   "source": [
    "from pydantic import ValidationError\n",
    "\n",
    "# Bind schema to model\n",
    "model_with_structure = model.with_structured_output(TelegramAndTrustFallPreferences)\n",
    "\n",
    "# Conversation\n",
    "conversation = \"\"\"Operator: How may I assist with your telegram, sir?\n",
    "Customer: I need to send a message about our trust fall exercise.\n",
    "Operator: Certainly. Morse code or standard encoding?\n",
    "Customer: Morse, please. I love using a straight key.\n",
    "Operator: Excellent. What's your message?\n",
    "Customer: Tell him I'm ready for a higher fall, and I prefer the diamond formation for catching.\n",
    "Operator: Done. Shall I use our \"Daredevil\" paper for this daring message?\n",
    "Customer: Perfect! Send it by your fastest carrier pigeon.\n",
    "Operator: It'll be there within the hour, sir.\"\"\"\n",
    "\n",
    "# Invoke the model\n",
    "try:\n",
    "    model_with_structure.invoke(f\"\"\"Extract the preferences from the following conversation:\n",
    "    <convo>\n",
    "    {conversation}\n",
    "    </convo>\"\"\")\n",
    "except ValidationError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TrustCall for Creating and Updating Profile Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith tracing is off\n"
     ]
    }
   ],
   "source": [
    "print(\"LangSmith tracing is\", \"on\" if os.environ.get(\"LANGSMITH_TRACING\", \"\").lower() == \"true\" else \"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock Conversation\n",
    "from langchain_core.messages import AIMessage\n",
    "conversation = [HumanMessage(content=\"Hi, I'm Manan.\"), \n",
    "                AIMessage(content=\"Nice to meet you, Manan.\"), \n",
    "                HumanMessage(content=\"I really like to read books and coding.\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We use `create_extractor`, passing in the model as well as our schema as a tool\n",
    "- Schema could be a JSON Object, Python Dict or Pydantic Model\n",
    "- Under the hood, `trustcall` uses tool_calling to produce **structured_outputs** from an **input list of messages**\n",
    "- To force trustcall to produce structured output, we can include the schema name in the `tool_choice` argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_zRaIyQqt2lKZr9DfJU5EJS4v', 'function': {'arguments': '{\"user_name\":\"Manan\",\"interests\":[\"reading books\",\"coding\"]}', 'name': 'UserProfile'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 133, 'total_tokens': 149, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'finish_reason': 'stop', 'logprobs': None}, id='run-2030f4e2-bba1-4b54-92dd-dec3fb87727b-0', tool_calls=[{'name': 'UserProfile', 'args': {'user_name': 'Manan', 'interests': ['reading books', 'coding']}, 'id': 'call_zRaIyQqt2lKZr9DfJU5EJS4v', 'type': 'tool_call'}], usage_metadata={'input_tokens': 133, 'output_tokens': 16, 'total_tokens': 149})],\n",
       " 'responses': [UserProfile(user_name='Manan', interests=['reading books', 'coding'])],\n",
       " 'response_metadata': [{'id': 'call_zRaIyQqt2lKZr9DfJU5EJS4v'}],\n",
       " 'attempts': 1}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trustcall import create_extractor\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Define the Schema\n",
    "class UserProfile(BaseModel):\n",
    "    \"\"\"UserProfile Schema with Typed fields\"\"\"\n",
    "    user_name: str = Field(description= \"The user's preffered name\")\n",
    "    interests: List[str] = Field(description=\"A list of User's Interests\")\n",
    "\n",
    "# Create the extractor\n",
    "trustcall_extractor = create_extractor(model, \n",
    "                                       tools = [UserProfile],\n",
    "                                       tool_choice=\"UserProfile\")\n",
    "# Instruction\n",
    "system_msg = \"Extract the user profile from the following conversation\"\n",
    "\n",
    "# Invoke the extractor\n",
    "from langchain_core.tracers.context import tracing_v2_enabled\n",
    "\n",
    "result = trustcall_extractor.invoke([SystemMessage(content=system_msg)] + conversation)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UserProfile (call_zRaIyQqt2lKZr9DfJU5EJS4v)\n",
      " Call ID: call_zRaIyQqt2lKZr9DfJU5EJS4v\n",
      "  Args:\n",
      "    user_name: Manan\n",
      "    interests: ['reading books', 'coding']\n"
     ]
    }
   ],
   "source": [
    "# The toolcalls it made\n",
    "result['messages'][0].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([UserProfile(user_name='Manan', interests=['reading books', 'coding'])], list)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = result['responses']\n",
    "schema, type(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_name': 'Manan', 'interests': ['reading books', 'coding']}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Into a dict\n",
    "schema[0].model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating an Existing Schema using TrustCall\n",
    "- It will take a set of conversation and existing schema\n",
    "- JSON patch: Will generate only the updates to be made\n",
    "- Benefits: Less prone to errors, more efficient as the number of tokens is minimized\n",
    "\n",
    "* We can save the existing schema as a dict\n",
    "* We can use `model_dump` to serialize a Pydantic model instance into a dict\n",
    "* We can pass it to 'existing' argument along with the schema name, `UserProfile`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_NTYWKESVaFIzjzVjlwAgacpp', 'function': {'arguments': '{\"user_name\":\"Manan\",\"interests\":[\"reading books\",\"coding\",\"Python\"]}', 'name': 'UserProfile'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 162, 'total_tokens': 180, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'finish_reason': 'stop', 'logprobs': None}, id='run-ffd584f1-437a-4ea4-8f4f-e9abf471f63c-0', tool_calls=[{'name': 'UserProfile', 'args': {'user_name': 'Manan', 'interests': ['reading books', 'coding', 'Python']}, 'id': 'call_NTYWKESVaFIzjzVjlwAgacpp', 'type': 'tool_call'}], usage_metadata={'input_tokens': 162, 'output_tokens': 18, 'total_tokens': 180})],\n",
       " 'responses': [UserProfile(user_name='Manan', interests=['reading books', 'coding', 'Python'])],\n",
       " 'response_metadata': [{'id': 'call_NTYWKESVaFIzjzVjlwAgacpp'}],\n",
       " 'attempts': 1}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update the conversation\n",
    "updated_conversation = [HumanMessage(content=\"Hi, I'm Manan.\"), \n",
    "                        AIMessage(content=\"Nice to meet you, Manan.\"), \n",
    "                        HumanMessage(content=\"I really like to read books and coding.\"),\n",
    "                        AIMessage(content=\"Great! Which language do you like the most?\"),\n",
    "                        HumanMessage(content=\"I love Python!\"),]\n",
    "\n",
    "# Updated instructions\n",
    "system_msg = f\"\"\"Update the memory (JSON doc) to incorporate new information from the following conversation\"\"\"\n",
    "\n",
    "# Invoking the extractor\n",
    "result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=system_msg)]+updated_conversation},\n",
    "                                    {'existing':{\"UserProfile\": schema[0].model_dump()}})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UserProfile (call_NTYWKESVaFIzjzVjlwAgacpp)\n",
      " Call ID: call_NTYWKESVaFIzjzVjlwAgacpp\n",
      "  Args:\n",
      "    user_name: Manan\n",
      "    interests: ['reading books', 'coding', 'Python']\n"
     ]
    }
   ],
   "source": [
    "result['messages'][0].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[UserProfile(user_name='Manan', interests=['reading books', 'coding', 'Python'])]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['responses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'call_NTYWKESVaFIzjzVjlwAgacpp'}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['response_metadata']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with Challenging Schema "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TelegramAndTrustFallPreferences(pertinent_user_preferences=UserPreferences(communication_preferences=CommunicationPreferences(telegram=TelegramPreferences(preferred_encoding=[OutputFormat(preference='standard encoding', sentence_preference_revealed='standard encoding')], favorite_telegram_operators=None, preferred_telegram_paper=[OutputFormat(preference='Daredevil', sentence_preference_revealed='Daredevil')]), morse_code=MorseCode(preferred_key_type=[OutputFormat(preference='straight key', sentence_preference_revealed='straight key')], favorite_morse_abbreviations=None), semaphore=Semaphore(preferred_flag_color=None, semaphore_skill_level=None)), trust_fall_preferences=TrustFallPreferences(preferred_fall_height=[OutputFormat(preference='higher', sentence_preference_revealed='higher')], trust_level=None, preferred_catching_technique=[OutputFormat(preference='diamond formation', sentence_preference_revealed='diamond formation')])))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "# Add model_copy method for compatibility\n",
    "AIMessage.model_copy = lambda self, deep=False: self.copy()\n",
    "HumanMessage.model_copy = lambda self, deep=False: self.copy()\n",
    "\n",
    "bound = create_extractor(\n",
    "    model,\n",
    "    tools=[TelegramAndTrustFallPreferences],\n",
    "    tool_choice=\"TelegramAndTrustFallPreferences\",\n",
    ")\n",
    "\n",
    "# Conversation\n",
    "conversation = \"\"\"Operator: How may I assist with your telegram, sir?\n",
    "Customer: I need to send a message about our trust fall exercise.\n",
    "Operator: Certainly. Morse code or standard encoding?\n",
    "Customer: Morse, please. I love using a straight key.\n",
    "Operator: Excellent. What's your message?\n",
    "Customer: Tell him I'm ready for a higher fall, and I prefer the diamond formation for catching.\n",
    "Operator: Done. Shall I use our \"Daredevil\" paper for this daring message?\n",
    "Customer: Perfect! Send it by your fastest carrier pigeon.\n",
    "Operator: It'll be there within the hour, sir.\"\"\"\n",
    "\n",
    "result = bound.invoke(\n",
    "    f\"\"\"Extract the preferences from the following conversation:\n",
    "<convo>\n",
    "{conversation}\n",
    "</convo>\"\"\"\n",
    ")\n",
    "\n",
    "# Extract the preferences\n",
    "result[\"responses\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pertinent_user_preferences': {'communication_preferences': {'telegram': {'preferred_encoding': [{'preference': 'standard encoding',\n",
       "      'sentence_preference_revealed': 'standard encoding'}],\n",
       "    'favorite_telegram_operators': None,\n",
       "    'preferred_telegram_paper': [{'preference': 'Daredevil',\n",
       "      'sentence_preference_revealed': 'Daredevil'}]},\n",
       "   'morse_code': {'preferred_key_type': [{'preference': 'straight key',\n",
       "      'sentence_preference_revealed': 'straight key'}],\n",
       "    'favorite_morse_abbreviations': None},\n",
       "   'semaphore': {'preferred_flag_color': None, 'semaphore_skill_level': None}},\n",
       "  'trust_fall_preferences': {'preferred_fall_height': [{'preference': 'higher',\n",
       "     'sentence_preference_revealed': 'higher'}],\n",
       "   'trust_level': None,\n",
       "   'preferred_catching_technique': [{'preference': 'diamond formation',\n",
       "     'sentence_preference_revealed': 'diamond formation'}]}}}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['responses'][0].model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbot with Profile Schema Updating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memory Structure to be Used:\n",
    "\n",
    "namespace = (user_id, 'memory')\n",
    "\n",
    "key = 'user_memory'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's write the whole chatbot on our own\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.graph.message import MessagesState\n",
    "from langgraph.store.memory import InMemoryStore, BaseStore\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "from trustcall import create_extractor\n",
    "\n",
    "# Create the Custom User Profile to be used\n",
    "class UserProfile(BaseModel):\n",
    "    user_name: str = Field(description=\"User's preffered name.\")\n",
    "    user_location: str = Field(description=\"Location of the User.\")\n",
    "    interests: List[str] = Field(description=\"A list of User's interests\")\n",
    "\n",
    "# Create the Trustcall extractor\n",
    "trustcall_extractor = create_extractor(model,\n",
    "                                       tools= [UserProfile],\n",
    "                                       tool_choice=\"UserProfile\")\n",
    "\n",
    "# Define the first node: A chatbot chatting while keeping user's history in mind\n",
    "CHAT_PROMPT = \"\"\"You are a helpful assisstant. Respond to the user's query while keeping memory about the user in mind.\n",
    "memory (It could be empty as well): {memory}\"\"\"\n",
    "\n",
    "def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Calls the model and talks to the user based on memory\"\"\"\n",
    "    # Get the user's memory from the store\n",
    "    user_id = config['configurable']['user_id']\n",
    "    namespace = (user_id, 'memory')\n",
    "    key = 'user_memory'\n",
    "\n",
    "    existing_memory = store.get(namespace,key)\n",
    "\n",
    "    # Format the memories for the system prompt\n",
    "    if existing_memory and existing_memory.value:\n",
    "        memory_dict = existing_memory.value\n",
    "        formatted_memory = (\n",
    "            f\"Name: {memory_dict.get('user_name', 'Unknown')}\\n\"\n",
    "            f\"Location: {memory_dict.get('user_location', 'Unknown')}\\n\"\n",
    "            f\"Interests: {', '.join(memory_dict.get('interests', []))}\"      \n",
    "        )\n",
    "    else:\n",
    "        formatted_memory = None\n",
    "    \n",
    "    # Format the system prompt\n",
    "    system_message = CHAT_PROMPT.format(memory = formatted_memory)\n",
    "\n",
    "    return {'messages':model.invoke([SystemMessage(content = system_message)] + state['messages'])}\n",
    "\n",
    "# Define the Second Node to update the memory\n",
    "TRUSTCALL_INSTRUCTION = \"\"\" \n",
    "Based on the given conversation, create or update the given memory (JSON doc)\"\"\"\n",
    "\n",
    "def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    # Get the user's memory from the store\n",
    "    user_id = config['configurable']['user_id']\n",
    "    namespace = (user_id, 'memory')\n",
    "    key = 'user_memory'\n",
    "\n",
    "    existing_memory = store.get(namespace, key)\n",
    "\n",
    "    if existing_memory is not None and getattr(existing_memory, \"value\", None) is not None:\n",
    "        existing_profile = {'UserProfile': existing_memory.value}\n",
    "    else:\n",
    "        existing_profile = None\n",
    "\n",
    "    # Invoke the extractor\n",
    "    result = trustcall_extractor.invoke({\n",
    "        \"messages\": [SystemMessage(content=TRUSTCALL_INSTRUCTION)] + state[\"messages\"],\n",
    "        'existing': existing_profile\n",
    "    })\n",
    "    # Get the updated profile as a JSON object\n",
    "    updated_profile = result['responses'][0].model_dump()\n",
    "    # Update the memory\n",
    "    store.put(namespace, key, updated_profile)\n",
    "\n",
    "# Define the graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_node(\"write_memory\", write_memory)\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_edge(\"call_model\", \"write_memory\")\n",
    "builder.add_edge(\"write_memory\", END)\n",
    "\n",
    "# Store for long-term (across-thread) memory\n",
    "across_thread_memory = InMemoryStore()\n",
    "\n",
    "# Checkpointer for short-term (within-thread) memory\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# Compile the graph with the checkpointer fir and store\n",
    "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, my name is Manan\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello, Manan! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input \n",
    "input_messages = [HumanMessage(content=\"Hi, my name is Manan\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, my name is Manan\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello, Manan! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# Check the checkpointer\n",
    "thread = {'configurable':{'thread_id':\"1\"}}\n",
    "state = graph.get_state(thread)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': ['1', 'memory'],\n",
       " 'key': 'user_memory',\n",
       " 'value': {'user_name': 'Manan', 'user_location': '', 'interests': []},\n",
       " 'created_at': '2025-06-29T20:02:09.501000+00:00',\n",
       " 'updated_at': '2025-06-29T20:02:09.501000+00:00'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the store\n",
    "user_id = \"1\"\n",
    "namespace = (user_id, 'memory')\n",
    "key = \"user_memory\"\n",
    "\n",
    "memory = across_thread_memory.get(namespace,key)\n",
    "memory.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I live in India. I love to read books and code!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's great, Manan! India has such a rich literary culture, and it's fantastic that you enjoy reading. Coding is a wonderful skill to have as well. Do you have any favorite books or programming languages you like to work with?\n"
     ]
    }
   ],
   "source": [
    "# User input \n",
    "input_messages = [HumanMessage(content=\"I live in India. I love to read books and code!\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, my name is Manan\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello, Manan! How can I assist you today?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I live in India. I love to read books and code!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's great, Manan! India has such a rich literary culture, and it's fantastic that you enjoy reading. Coding is a wonderful skill to have as well. Do you have any favorite books or programming languages you like to work with?\n"
     ]
    }
   ],
   "source": [
    "# Check the checkpointer\n",
    "thread = {'configurable':{'thread_id':\"1\"}}\n",
    "state = graph.get_state(thread)\n",
    "for m in state.values['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': ['1', 'memory'],\n",
       " 'key': 'user_memory',\n",
       " 'value': {'user_name': 'Manan',\n",
       "  'user_location': 'India',\n",
       "  'interests': ['reading books', 'coding']},\n",
       " 'created_at': '2025-06-29T20:05:02.931368+00:00',\n",
       " 'updated_at': '2025-06-29T20:05:02.931368+00:00'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the store\n",
    "user_id = \"1\"\n",
    "namespace = (user_id, 'memory')\n",
    "key = \"user_memory\"\n",
    "\n",
    "memory = across_thread_memory.get(namespace,key)\n",
    "memory.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
